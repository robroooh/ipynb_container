{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 train samples\n",
      "10000 test samples\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_52 (Dense)                 (None, 512)           401920      dense_input_18[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_52 (Activation)       (None, 512)           0           dense_52[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_53 (Dense)                 (None, 512)           262656      activation_52[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_53 (Activation)       (None, 512)           0           dense_53[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_54 (Dense)                 (None, 10)            5130        activation_53[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_54 (Activation)       (None, 10)            0           dense_54[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 669706\n",
      "____________________________________________________________________________________________________\n",
      "Test score: 0.0179820289901\n",
      "Test accuracy: 0.8806\n",
      "Train score: 0.00241962236166\n",
      "Train accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2, activity_l2\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "nb_classes = 10\n",
    "nb_epoch = 400\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "\n",
    "X_train_10000 = X_train[:1000]\n",
    "X_test_10000 = X_test[:10000]\n",
    "\n",
    "X_train_10000 = X_train_10000.astype('float32')\n",
    "X_test_10000 = X_test_10000.astype('float32')\n",
    "X_train_10000 /= 255\n",
    "X_test_10000 /= 255\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(X_train_10000.shape[0], 'train samples')\n",
    "print(X_test_10000.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train[:1000], nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test[:10000], nb_classes)\n",
    "\n",
    "FC0 = Dense(512, W_regularizer=l2(0), input_shape=(784,))\n",
    "FC1 = Dense(512)\n",
    "FC2 = Dense(10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(FC0)\n",
    "model.add(Activation('relu'))\n",
    "model.add(FC1)\n",
    "model.add(Activation('relu'))\n",
    "model.add(FC2)\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_10000, Y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=0, validation_data=(X_test_10000, Y_test))\n",
    "score = model.evaluate(X_test_10000, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "score = model.evaluate(X_train_10000, Y_train, verbose=0)\n",
    "print('Train score:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    " 1. Train the mlp network setting l2 = 0, get the LOSS\n",
    " 2. Save the weight \n",
    " 3. Alter one of the particular weight\n",
    " 4. load the weight back into the network\n",
    " 5. feed input and set training = false\n",
    " 6. get $ \\frac{\\delta L}{\\delta wij} $\n",
    " 7. calculate $ \\lambda = -\\frac{1}{2}\\frac{1}{\\sum_j^{nw}\\sum_i^{nw} W_ij} $\n",
    " 8. use the lambda in reg. and measure the accuracy b4 and after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording result\n",
    "\n",
    "### 3 Layers 512 512 10 l2 on the last layer only\n",
    " - epoch=3, l2=0, acc=0.9734,0.9734\n",
    " - epoch=3, l2=100, acc=0.9657,0.9657\n",
    " \n",
    "### 2 Layers 512 10 l2 on the first layer\n",
    " - epoch=3, l2=100, acc= 0.9631\n",
    " - epoch=3, l2=0, acc= 0.9636\n",
    " - epoch=3, l2=0.00001, acc= 0.9638\n",
    " \n",
    "### 2 Layers 4096 10 L2 on the first layer\n",
    " - ep=3, l2 = 0.00001, Test accuracy: 0.9748\n",
    " - ep=3, l2 = 10000, Test accuracy: 0.9597, 0.9597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers_weights = [model.layers[0].get_weights(), model.layers[2].get_weights(),model.layers[4].get_weights()]\n",
    "l_wrt_w = np.zeros(layers_weights[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minw, maxw =  -0.102813 0.119484\n"
     ]
    }
   ],
   "source": [
    "# find max min of weight\n",
    "minw = np.amin(np.amin(l0_ww, axis=0))\n",
    "maxw = np.amax(np.amax(l0_ww, axis=0))\n",
    "print(\"minw, maxw = \", minw, maxw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.uniform(minw,maxw)\n",
    "\n",
    "layer_0_altered_weight = np.copy(layers_weights[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "print(layers_weights[0][0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalty layer0's weight to 20, the network is still overfitting\n",
    " - How to adjust the weight, tried min,max does not see much changes\n",
    " - how to check for Loss wrt weight, think about delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At index i,j =  0 0\n",
      "Test score: 0.0179820289901\n",
      "Test accuracy: 0.8806\n",
      "Train score: 0.00241962236166\n",
      "Train accuracy: 0.988\n",
      "At index i,j =  0 1\n",
      "Test score: 0.0179820289901\n",
      "Test accuracy: 0.8806\n",
      "Train score: 0.00241962236166\n",
      "Train accuracy: 0.988\n",
      "At index i,j =  0 2\n",
      "Test score: 0.0179820289901\n",
      "Test accuracy: 0.8806\n",
      "Train score: 0.00241962236166\n",
      "Train accuracy: 0.988\n",
      "At index i,j =  0 3\n",
      "Test score: 0.0179820289901\n",
      "Test accuracy: 0.8806\n",
      "Train score: 0.00241962236166\n",
      "Train accuracy: 0.988\n",
      "At index i,j =  0 4\n",
      "Test score: 0.0179820289901\n",
      "Test accuracy: 0.8806\n",
      "Train score: 0.00241962236166\n",
      "Train accuracy: 0.988\n",
      "At index i,j =  0 5\n",
      "Test score: 0.0179820289901\n",
      "Test accuracy: 0.8806\n",
      "Train score: 0.00241962236166\n",
      "Train accuracy: 0.988\n",
      "At index i,j =  0 6\n",
      "Test score: 0.0179820289901\n",
      "Test accuracy: 0.8806\n",
      "Train score: 0.00241962236166\n",
      "Train accuracy: 0.988\n",
      "At index i,j =  0 7\n",
      "Test score: 0.0179820289901\n",
      "Test accuracy: 0.8806\n",
      "Train score: 0.00241962236166\n",
      "Train accuracy: 0.988\n",
      "At index i,j =  0 8\n",
      "Test score: 0.0179820289901\n",
      "Test accuracy: 0.8806\n",
      "Train score: 0.00241962236166\n",
      "Train accuracy: 0.988\n",
      "At index i,j =  0 9\n",
      "Test score: 0.0179820289901\n",
      "Test accuracy: 0.8806\n",
      "Train score: 0.00241962236166\n",
      "Train accuracy: 0.988\n",
      "At index i,j =  0 10\n",
      "Test score: 0.0179820289901\n",
      "Test accuracy: 0.8806\n",
      "Train score: 0.00241962236166\n",
      "Train accuracy: 0.988\n",
      "At index i,j =  0 11\n",
      "Test score: 0.0179820289901\n",
      "Test accuracy: 0.8806\n",
      "Train score: 0.00241962236166\n",
      "Train accuracy: 0.988\n",
      "At index i,j =  0 12\n",
      "Test score: 0.0179820289901\n",
      "Test accuracy: 0.8806\n",
      "Train score: 0.00241962236166\n",
      "Train accuracy: 0.988\n",
      "At index i,j =  0 13\n",
      "Test score: 0.0179820289901\n",
      "Test accuracy: 0.8806\n",
      "Train score: 0.00241962236166\n",
      "Train accuracy: 0.988\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-158-afce3878cd24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0ml_wrt_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m                                    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                                    sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         return self._test_loop(f, ins,\n\u001b[1;32m   1144\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m                                verbose=verbose)\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(l_wrt_w.shape[0]):\n",
    "    for j in range(l_wrt_w.shape[1]):\n",
    "        \n",
    "        layer_0_altered_weight[0][i][j] = 20\n",
    "                \n",
    "        for idx in [0,2,4]:\n",
    "            model.layers[idx].trainable = False\n",
    "        \n",
    "        model.layers[0].set_weights(layer_0_altered_weight)\n",
    "        model.layers[2].set_weights(layers_weights[1])\n",
    "        model.layers[4].set_weights(layers_weights[2])\n",
    "        \n",
    "        score = model.evaluate(X_test_10000, Y_test, verbose=0)\n",
    "        l_wrt_w[i][j] = score[0]\n",
    "        \n",
    "        print('At index i,j = ', i, j)\n",
    "        print('Test score:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        score = model.evaluate(X_train_10000, Y_train, verbose=0)\n",
    "        print('Train score:', score[0])\n",
    "        print('Train accuracy:', score[1])\n",
    "        \n",
    "        layer_0_altered_weight = np.copy(layers_weights[0])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01798203  0.01798203  0.01798203  0.01798203  0.01798203  0.01798203\n",
      "  0.01798203  0.01798203  0.01798203  0.01798203  0.01798203  0.01798203\n",
      "  0.01798203  0.01798203  0.01798203  0.01798203  0.01798203  0.01798203\n",
      "  0.01798203  0.01798203  0.01798203]\n"
     ]
    }
   ],
   "source": [
    "print (l_wrt_w[0][:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_58 (Dense)                 (None, 512)           401920      dense_input_20[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_58 (Activation)       (None, 512)           0           dense_58[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_59 (Dense)                 (None, 512)           262656      activation_58[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_59 (Activation)       (None, 512)           0           dense_59[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_60 (Dense)                 (None, 10)            5130        activation_59[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_60 (Activation)       (None, 10)            0           dense_60[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 669706\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "FC0 = Dense(512, W_regularizer=l2(0), input_shape=(784,), trainable=False)\n",
    "FC1 = Dense(512, trainable=False)\n",
    "FC2 = Dense(10, trainable=False)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(FC0)\n",
    "model.add(Activation('relu'))\n",
    "model.add(FC1)\n",
    "model.add(Activation('relu'))\n",
    "model.add(FC2)\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.layers[0].set_weights(l0_w)\n",
    "model.layers[2].set_weights(l2_w)\n",
    "model.layers[4].set_weights(l4_w)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.0179820289901\n",
      "Test accuracy: 0.8806\n",
      "Train score: 0.00241962236166\n",
      "Train accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_10000, Y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=0, validation_data=(X_test_10000, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test_10000, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "score = model.evaluate(X_train_10000, Y_train, verbose=0)\n",
    "print('Train score:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
