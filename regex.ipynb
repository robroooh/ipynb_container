{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in1 = \"X_train shape: (50000, 3072)\\n50000 train samples\\n10000 test samples\\nthe reg is at  =  1e-06\\n(The weight is init at l1 = , array(0.0, dtype=float32),  l2 = , array(9.999999974752427e-07, dtype=float32))\\n(param = , dense_3_W)\\n(The reg_loss is called, Elemwise{add,no_inplace}.0)\\nTrain on 20000 samples, validate on 10000 samples\\nEpoch 1/40\\n20000/20000 [==============================] - 41s - loss: 0.0962 - acc: 0.2382 - val_loss: 0.0831 - val_acc: 0.3036\\nEpoch 2/40\\n20000/20000 [==============================] - 41s - loss: 0.0798 - acc: 0.3422 - val_loss: 0.0782 - val_acc: 0.3596\\nEpoch 3/40\\n20000/20000 [==============================] - 41s - loss: 0.0764 - acc: 0.3890 - val_loss: 0.0756 - val_acc: 0.3941\\nEpoch 4/40\\n20000/20000 [==============================] - 41s - loss: 0.0741 - acc: 0.4106 - val_loss: 0.0768 - val_acc: 0.3862\\nEpoch 5/40\\n20000/20000 [==============================] - 44s - loss: 0.0721 - acc: 0.4346 - val_loss: 0.0735 - val_acc: 0.4217\\nEpoch 6/40\\n20000/20000 [==============================] - 48s - loss: 0.0704 - acc: 0.4561 - val_loss: 0.0716 - val_acc: 0.4405\\nEpoch 7/40\\n20000/20000 [==============================] - 50s - loss: 0.0692 - acc: 0.4678 - val_loss: 0.0719 - val_acc: 0.4347\\nEpoch 8/40\\n20000/20000 [==============================] - 51s - loss: 0.0678 - acc: 0.4852 - val_loss: 0.0713 - val_acc: 0.4421\\nEpoch 9/40\\n20000/20000 [==============================] - 52s - loss: 0.0666 - acc: 0.4946 - val_loss: 0.0746 - val_acc: 0.4168\\nEpoch 10/40\\n20000/20000 [==============================] - 53s - loss: 0.0654 - acc: 0.5095 - val_loss: 0.0712 - val_acc: 0.4515\\nEpoch 11/40\\n20000/20000 [==============================] - 55s - loss: 0.0643 - acc: 0.5176 - val_loss: 0.0709 - val_acc: 0.4500\\nEpoch 12/40\\n20000/20000 [==============================] - 56s - loss: 0.0632 - acc: 0.5310 - val_loss: 0.0692 - val_acc: 0.4716\\nEpoch 13/40\\n20000/20000 [==============================] - 57s - loss: 0.0622 - acc: 0.5425 - val_loss: 0.0698 - val_acc: 0.4732\\nEpoch 14/40\\n20000/20000 [==============================] - 57s - loss: 0.0612 - acc: 0.5548 - val_loss: 0.0692 - val_acc: 0.4696\\nEpoch 15/40\\n20000/20000 [==============================] - 59s - loss: 0.0600 - acc: 0.5667 - val_loss: 0.0692 - val_acc: 0.4725\\nEpoch 16/40\\n20000/20000 [==============================] - 59s - loss: 0.0592 - acc: 0.5794 - val_loss: 0.0719 - val_acc: 0.4598\\nEpoch 17/40\\n20000/20000 [==============================] - 58s - loss: 0.0580 - acc: 0.5897 - val_loss: 0.0700 - val_acc: 0.4719\\nEpoch 18/40\\n20000/20000 [==============================] - 59s - loss: 0.0571 - acc: 0.5992 - val_loss: 0.0729 - val_acc: 0.4555\\nEpoch 19/40\\n20000/20000 [==============================] - 59s - loss: 0.0560 - acc: 0.6128 - val_loss: 0.0706 - val_acc: 0.4629\\nEpoch 20/40\\n20000/20000 [==============================] - 59s - loss: 0.0551 - acc: 0.6197 - val_loss: 0.0689 - val_acc: 0.4840\\nEpoch 21/40\\n20000/20000 [==============================] - 59s - loss: 0.0542 - acc: 0.6309 - val_loss: 0.0690 - val_acc: 0.4869\\nEpoch 22/40\\n20000/20000 [==============================] - 60s - loss: 0.0531 - acc: 0.6428 - val_loss: 0.0709 - val_acc: 0.4746\\nEpoch 23/40\\n20000/20000 [==============================] - 61s - loss: 0.0522 - acc: 0.6522 - val_loss: 0.0715 - val_acc: 0.4670\\nEpoch 24/40\\n20000/20000 [==============================] - 61s - loss: 0.0512 - acc: 0.6620 - val_loss: 0.0690 - val_acc: 0.4921\\nEpoch 25/40\\n20000/20000 [==============================] - 61s - loss: 0.0504 - acc: 0.6698 - val_loss: 0.0688 - val_acc: 0.4912\\nEpoch 26/40\\n20000/20000 [==============================] - 62s - loss: 0.0494 - acc: 0.6782 - val_loss: 0.0693 - val_acc: 0.4866\\nEpoch 27/40\\n20000/20000 [==============================] - 61s - loss: 0.0486 - acc: 0.6873 - val_loss: 0.0697 - val_acc: 0.4918\\nEpoch 28/40\\n20000/20000 [==============================] - 62s - loss: 0.0476 - acc: 0.6976 - val_loss: 0.0689 - val_acc: 0.4941\\nEpoch 29/40\\n20000/20000 [==============================] - 62s - loss: 0.0467 - acc: 0.7091 - val_loss: 0.0699 - val_acc: 0.4805\\nEpoch 30/40\\n20000/20000 [==============================] - 62s - loss: 0.0459 - acc: 0.7169 - val_loss: 0.0715 - val_acc: 0.4825\\nEpoch 31/40\\n20000/20000 [==============================] - 63s - loss: 0.0449 - acc: 0.7262 - val_loss: 0.0681 - val_acc: 0.5099\\nEpoch 32/40\\n20000/20000 [==============================] - 61s - loss: 0.0441 - acc: 0.7319 - val_loss: 0.0705 - val_acc: 0.4910\\nEpoch 33/40\\n20000/20000 [==============================] - 62s - loss: 0.0433 - acc: 0.7408 - val_loss: 0.0700 - val_acc: 0.4997\\nEpoch 34/40\\n20000/20000 [==============================] - 62s - loss: 0.0425 - acc: 0.7518 - val_loss: 0.0707 - val_acc: 0.4923\\nEpoch 35/40\\n20000/20000 [==============================] - 63s - loss: 0.0417 - acc: 0.7579 - val_loss: 0.0713 - val_acc: 0.4917\\nEpoch 36/40\\n20000/20000 [==============================] - 64s - loss: 0.0409 - acc: 0.7655 - val_loss: 0.0713 - val_acc: 0.4896\\nEpoch 37/40\\n20000/20000 [==============================] - 64s - loss: 0.0401 - acc: 0.7708 - val_loss: 0.0730 - val_acc: 0.4824\\nEpoch 38/40\\n20000/20000 [==============================] - 64s - loss: 0.0394 - acc: 0.7785 - val_loss: 0.0719 - val_acc: 0.4807\\nEpoch 39/40\\n20000/20000 [==============================] - 65s - loss: 0.0387 - acc: 0.7871 - val_loss: 0.0708 - val_acc: 0.5001\\nEpoch 40/40\\n20000/20000 [==============================] - 65s - loss: 0.0380 - acc: 0.7926 - val_loss: 0.0733 - val_acc: 0.4817\\n ========================== \\nthe smallest weight is =  -0.261926\\nthe biggest weight is =  0.492996\\nthe most mainstream order is as follow\\n[(1.00E+02, 3645), (1.00E+01, 643), (1.00E+03, 506), (1.00E+04, 49), (1.00E+05, 6), (1.00E+06, 1)]\\n ========================== \\nthe reg is at  =  1e-05\\n(The weight is init at l1 = , array(0.0, dtype=float32),  l2 = , array(9.999999747378752e-06, dtype=float32))\\n(param = , dense_6_W)\\n(The reg_loss is called, Elemwise{add,no_inplace}.0)\\nTrain on 20000 samples, validate on 10000 samples\\nEpoch 1/40\\n20000/20000 [==============================] - 39s - loss: 0.0970 - acc: 0.2462 - val_loss: 0.0823 - val_acc: 0.2889\\nEpoch 2/40\\n20000/20000 [==============================] - 38s - loss: 0.0798 - acc: 0.3458 - val_loss: 0.0771 - val_acc: 0.3713\\nEpoch 3/40\\n20000/20000 [==============================] - 39s - loss: 0.0762 - acc: 0.3859 - val_loss: 0.0752 - val_acc: 0.3884\\nEpoch 4/40\\n20000/20000 [==============================] - 40s - loss: 0.0741 - acc: 0.4106 - val_loss: 0.0779 - val_acc: 0.3850\\nEpoch 5/40\\n20000/20000 [==============================] - 41s - loss: 0.0723 - acc: 0.4309 - val_loss: 0.0726 - val_acc: 0.4267\\nEpoch 6/40\\n20000/20000 [==============================] - 44s - loss: 0.0708 - acc: 0.4497 - val_loss: 0.0728 - val_acc: 0.4239\\nEpoch 7/40\\n20000/20000 [==============================] - 45s - loss: 0.0693 - acc: 0.4629 - val_loss: 0.0720 - val_acc: 0.4433\\nEpoch 8/40\\n20000/20000 [==============================] - 47s - loss: 0.0682 - acc: 0.4775 - val_loss: 0.0702 - val_acc: 0.4522\\nEpoch 9/40\\n20000/20000 [==============================] - 48s - loss: 0.0669 - acc: 0.4952 - val_loss: 0.0715 - val_acc: 0.4416\\nEpoch 10/40\\n20000/20000 [==============================] - 49s - loss: 0.0658 - acc: 0.5036 - val_loss: 0.0713 - val_acc: 0.4449\\nEpoch 11/40\\n20000/20000 [==============================] - 50s - loss: 0.0647 - acc: 0.5149 - val_loss: 0.0690 - val_acc: 0.4617\\nEpoch 12/40\\n20000/20000 [==============================] - 50s - loss: 0.0637 - acc: 0.5302 - val_loss: 0.0718 - val_acc: 0.4385\\nEpoch 13/40\\n20000/20000 [==============================] - 50s - loss: 0.0627 - acc: 0.5413 - val_loss: 0.0707 - val_acc: 0.4641\\nEpoch 14/40\\n20000/20000 [==============================] - 52s - loss: 0.0615 - acc: 0.5528 - val_loss: 0.0698 - val_acc: 0.4620\\nEpoch 15/40\\n20000/20000 [==============================] - 53s - loss: 0.0606 - acc: 0.5615 - val_loss: 0.0692 - val_acc: 0.4742\\nEpoch 16/40\\n20000/20000 [==============================] - 54s - loss: 0.0596 - acc: 0.5781 - val_loss: 0.0711 - val_acc: 0.4562\\nEpoch 17/40\\n20000/20000 [==============================] - 55s - loss: 0.0586 - acc: 0.5858 - val_loss: 0.0680 - val_acc: 0.4849\\nEpoch 18/40\\n20000/20000 [==============================] - 56s - loss: 0.0575 - acc: 0.5956 - val_loss: 0.0695 - val_acc: 0.4710\\nEpoch 19/40\\n20000/20000 [==============================] - 55s - loss: 0.0565 - acc: 0.6080 - val_loss: 0.0702 - val_acc: 0.4625\\nEpoch 20/40\\n20000/20000 [==============================] - 55s - loss: 0.0557 - acc: 0.6160 - val_loss: 0.0691 - val_acc: 0.4777\\nEpoch 21/40\\n20000/20000 [==============================] - 56s - loss: 0.0547 - acc: 0.6282 - val_loss: 0.0691 - val_acc: 0.4806\\nEpoch 22/40\\n20000/20000 [==============================] - 56s - loss: 0.0538 - acc: 0.6367 - val_loss: 0.0697 - val_acc: 0.4772\\nEpoch 23/40\\n20000/20000 [==============================] - 56s - loss: 0.0526 - acc: 0.6476 - val_loss: 0.0688 - val_acc: 0.4905\\nEpoch 24/40\\n20000/20000 [==============================] - 56s - loss: 0.0519 - acc: 0.6569 - val_loss: 0.0714 - val_acc: 0.4690\\nEpoch 25/40\\n20000/20000 [==============================] - 57s - loss: 0.0510 - acc: 0.6666 - val_loss: 0.0711 - val_acc: 0.4743\\nEpoch 26/40\\n20000/20000 [==============================] - 56s - loss: 0.0501 - acc: 0.6744 - val_loss: 0.0702 - val_acc: 0.4801\\nEpoch 27/40\\n20000/20000 [==============================] - 57s - loss: 0.0491 - acc: 0.6862 - val_loss: 0.0700 - val_acc: 0.4809\\nEpoch 28/40\\n20000/20000 [==============================] - 57s - loss: 0.0481 - acc: 0.6997 - val_loss: 0.0693 - val_acc: 0.4919\\nEpoch 29/40\\n20000/20000 [==============================] - 57s - loss: 0.0473 - acc: 0.7056 - val_loss: 0.0698 - val_acc: 0.4885\\nEpoch 30/40\\n20000/20000 [==============================] - 56s - loss: 0.0463 - acc: 0.7158 - val_loss: 0.0704 - val_acc: 0.4805\\nEpoch 31/40\\n20000/20000 [==============================] - 56s - loss: 0.0455 - acc: 0.7219 - val_loss: 0.0710 - val_acc: 0.4812\\nEpoch 32/40\\n20000/20000 [==============================] - 56s - loss: 0.0446 - acc: 0.7330 - val_loss: 0.0700 - val_acc: 0.4892\\nEpoch 33/40\\n20000/20000 [==============================] - 57s - loss: 0.0439 - acc: 0.7392 - val_loss: 0.0718 - val_acc: 0.4876\\nEpoch 34/40\\n20000/20000 [==============================] - 57s - loss: 0.0430 - acc: 0.7486 - val_loss: 0.0692 - val_acc: 0.4959\\nEpoch 35/40\\n20000/20000 [==============================] - 58s - loss: 0.0421 - acc: 0.7574 - val_loss: 0.0733 - val_acc: 0.4770\\nEpoch 36/40\\n20000/20000 [==============================] - 58s - loss: 0.0414 - acc: 0.7653 - val_loss: 0.0706 - val_acc: 0.4843\\nEpoch 37/40\\n20000/20000 [==============================] - 58s - loss: 0.0407 - acc: 0.7703 - val_loss: 0.0716 - val_acc: 0.4907\\nEpoch 38/40\\n20000/20000 [==============================] - 57s - loss: 0.0398 - acc: 0.7794 - val_loss: 0.0721 - val_acc: 0.4886\\nEpoch 39/40\\n20000/20000 [==============================] - 58s - loss: 0.0391 - acc: 0.7860 - val_loss: 0.0714 - val_acc: 0.4916\\nEpoch 40/40\\n20000/20000 [==============================] - 56s - loss: 0.0383 - acc: 0.7939 - val_loss: 0.0711 - val_acc: 0.4940\\n ========================== \\nthe smallest weight is =  -0.247513\\nthe biggest weight is =  0.470546\\nthe most mainstream order is as follow\\n[(1.00E+02, 3590), (1.00E+01, 670), (1.00E+03, 548), (1.00E+04, 56), (1.00E+05, 3), (1.00E+06, 3)]\\n ========================== \\nthe reg is at  =  0.0001\\n(The weight is init at l1 = , array(0.0, dtype=float32),  l2 = , array(9.999999747378752e-05, dtype=float32))\\n(param = , dense_9_W)\\n(The reg_loss is called, Elemwise{add,no_inplace}.0)\\nTrain on 20000 samples, validate on 10000 samples\\nEpoch 1/40\\n20000/20000 [==============================] - 38s - loss: 0.0988 - acc: 0.2408 - val_loss: 0.0824 - val_acc: 0.2950\\nEpoch 2/40\\n20000/20000 [==============================] - 39s - loss: 0.0801 - acc: 0.3343 - val_loss: 0.0773 - val_acc: 0.3778\\nEpoch 3/40\\n20000/20000 [==============================] - 39s - loss: 0.0767 - acc: 0.3835 - val_loss: 0.0754 - val_acc: 0.3929\\nEpoch 4/40\\n20000/20000 [==============================] - 42s - loss: 0.0743 - acc: 0.4070 - val_loss: 0.0751 - val_acc: 0.3958\\nEpoch 5/40\\n20000/20000 [==============================] - 46s - loss: 0.0722 - acc: 0.4314 - val_loss: 0.0715 - val_acc: 0.4380\\nEpoch 6/40\\n20000/20000 [==============================] - 47s - loss: 0.0706 - acc: 0.4527 - val_loss: 0.0737 - val_acc: 0.4129\\nEpoch 7/40\\n20000/20000 [==============================] - 47s - loss: 0.0693 - acc: 0.4647 - val_loss: 0.0713 - val_acc: 0.4406\\nEpoch 8/40\\n20000/20000 [==============================] - 48s - loss: 0.0681 - acc: 0.4777 - val_loss: 0.0714 - val_acc: 0.4372\\nEpoch 9/40\\n20000/20000 [==============================] - 49s - loss: 0.0668 - acc: 0.4952 - val_loss: 0.0701 - val_acc: 0.4566\\nEpoch 10/40\\n20000/20000 [==============================] - 50s - loss: 0.0656 - acc: 0.5048 - val_loss: 0.0709 - val_acc: 0.4460\\nEpoch 11/40\\n20000/20000 [==============================] - 52s - loss: 0.0643 - acc: 0.5192 - val_loss: 0.0698 - val_acc: 0.4603\\nEpoch 12/40\\n20000/20000 [==============================] - 53s - loss: 0.0633 - acc: 0.5319 - val_loss: 0.0704 - val_acc: 0.4599\\nEpoch 13/40\\n20000/20000 [==============================] - 53s - loss: 0.0623 - acc: 0.5436 - val_loss: 0.0697 - val_acc: 0.4667\\nEpoch 14/40\\n20000/20000 [==============================] - 54s - loss: 0.0611 - acc: 0.5545 - val_loss: 0.0696 - val_acc: 0.4629\\nEpoch 15/40\\n20000/20000 [==============================] - 55s - loss: 0.0602 - acc: 0.5631 - val_loss: 0.0702 - val_acc: 0.4526\\nEpoch 16/40\\n20000/20000 [==============================] - 56s - loss: 0.0593 - acc: 0.5763 - val_loss: 0.0690 - val_acc: 0.4721\\nEpoch 17/40\\n20000/20000 [==============================] - 56s - loss: 0.0583 - acc: 0.5857 - val_loss: 0.0712 - val_acc: 0.4543\\nEpoch 18/40\\n20000/20000 [==============================] - 56s - loss: 0.0571 - acc: 0.5968 - val_loss: 0.0697 - val_acc: 0.4724\\nEpoch 19/40\\n20000/20000 [==============================] - 57s - loss: 0.0562 - acc: 0.6107 - val_loss: 0.0752 - val_acc: 0.4236\\nEpoch 20/40\\n20000/20000 [==============================] - 57s - loss: 0.0552 - acc: 0.6161 - val_loss: 0.0695 - val_acc: 0.4805\\nEpoch 21/40\\n20000/20000 [==============================] - 57s - loss: 0.0542 - acc: 0.6350 - val_loss: 0.0682 - val_acc: 0.4934\\nEpoch 22/40\\n20000/20000 [==============================] - 57s - loss: 0.0533 - acc: 0.6404 - val_loss: 0.0684 - val_acc: 0.4828\\nEpoch 23/40\\n20000/20000 [==============================] - 57s - loss: 0.0523 - acc: 0.6520 - val_loss: 0.0701 - val_acc: 0.4802\\nEpoch 24/40\\n20000/20000 [==============================] - 57s - loss: 0.0514 - acc: 0.6614 - val_loss: 0.0711 - val_acc: 0.4723\\nEpoch 25/40\\n20000/20000 [==============================] - 58s - loss: 0.0506 - acc: 0.6697 - val_loss: 0.0686 - val_acc: 0.4903\\nEpoch 26/40\\n20000/20000 [==============================] - 57s - loss: 0.0495 - acc: 0.6804 - val_loss: 0.0702 - val_acc: 0.4805\\nEpoch 27/40\\n20000/20000 [==============================] - 58s - loss: 0.0486 - acc: 0.6878 - val_loss: 0.0702 - val_acc: 0.4806\\nEpoch 28/40\\n20000/20000 [==============================] - 58s - loss: 0.0480 - acc: 0.6935 - val_loss: 0.0693 - val_acc: 0.4899\\nEpoch 29/40\\n20000/20000 [==============================] - 58s - loss: 0.0469 - acc: 0.7067 - val_loss: 0.0705 - val_acc: 0.4866\\nEpoch 30/40\\n20000/20000 [==============================] - 58s - loss: 0.0461 - acc: 0.7130 - val_loss: 0.0700 - val_acc: 0.4951\\nEpoch 31/40\\n20000/20000 [==============================] - 59s - loss: 0.0452 - acc: 0.7203 - val_loss: 0.0722 - val_acc: 0.4759\\nEpoch 32/40\\n20000/20000 [==============================] - 59s - loss: 0.0443 - acc: 0.7326 - val_loss: 0.0703 - val_acc: 0.4887\\nEpoch 33/40\\n20000/20000 [==============================] - 59s - loss: 0.0435 - acc: 0.7396 - val_loss: 0.0710 - val_acc: 0.4873\\nEpoch 34/40\\n20000/20000 [==============================] - 59s - loss: 0.0426 - acc: 0.7512 - val_loss: 0.0717 - val_acc: 0.4773\\nEpoch 35/40\\n20000/20000 [==============================] - 59s - loss: 0.0421 - acc: 0.7543 - val_loss: 0.0699 - val_acc: 0.4977\\nEpoch 36/40\\n20000/20000 [==============================] - 59s - loss: 0.0413 - acc: 0.7596 - val_loss: 0.0699 - val_acc: 0.4987\\nEpoch 37/40\\n20000/20000 [==============================] - 59s - loss: 0.0403 - acc: 0.7713 - val_loss: 0.0736 - val_acc: 0.4822\\nEpoch 38/40\\n20000/20000 [==============================] - 59s - loss: 0.0396 - acc: 0.7763 - val_loss: 0.0710 - val_acc: 0.4906\\nEpoch 39/40\\n20000/20000 [==============================] - 59s - loss: 0.0388 - acc: 0.7832 - val_loss: 0.0713 - val_acc: 0.4869\\nEpoch 40/40\\n20000/20000 [==============================] - 60s - loss: 0.0381 - acc: 0.7934 - val_loss: 0.0726 - val_acc: 0.4897\\n ========================== \\nthe smallest weight is =  -0.257839\\nthe biggest weight is =  0.421273\\nthe most mainstream order is as follow\\n[(1.00E+02, 3638), (1.00E+01, 688), (1.00E+03, 485), (1.00E+04, 56), (1.00E+05, 7)]\\n ========================== \\nthe reg is at  =  0.001\\n(The weight is init at l1 = , array(0.0, dtype=float32),  l2 = , array(0.0010000000474974513, dtype=float32))\\n(param = , dense_12_W)\\n(The reg_loss is called, Elemwise{add,no_inplace}.0)\\nTrain on 20000 samples, validate on 10000 samples\\nEpoch 1/40\\n20000/20000 [==============================] - 39s - loss: 0.1001 - acc: 0.2415 - val_loss: 0.0811 - val_acc: 0.3265\\nEpoch 2/40\\n20000/20000 [==============================] - 39s - loss: 0.0800 - acc: 0.3405 - val_loss: 0.0799 - val_acc: 0.3366\\nEpoch 3/40\\n20000/20000 [==============================] - 39s - loss: 0.0766 - acc: 0.3816 - val_loss: 0.0782 - val_acc: 0.3654\\nEpoch 4/40\\n20000/20000 [==============================] - 42s - loss: 0.0742 - acc: 0.4092 - val_loss: 0.0737 - val_acc: 0.4129\\nEpoch 5/40\\n20000/20000 [==============================] - 43s - loss: 0.0724 - acc: 0.4309 - val_loss: 0.0733 - val_acc: 0.4314\\nEpoch 6/40\\n20000/20000 [==============================] - 46s - loss: 0.0708 - acc: 0.4466 - val_loss: 0.0737 - val_acc: 0.4211\\nEpoch 7/40\\n20000/20000 [==============================] - 47s - loss: 0.0694 - acc: 0.4636 - val_loss: 0.0718 - val_acc: 0.4423\\nEpoch 8/40\\n20000/20000 [==============================] - 48s - loss: 0.0681 - acc: 0.4787 - val_loss: 0.0724 - val_acc: 0.4354\\nEpoch 9/40\\n20000/20000 [==============================] - 48s - loss: 0.0667 - acc: 0.4963 - val_loss: 0.0713 - val_acc: 0.4528\\nEpoch 10/40\\n20000/20000 [==============================] - 49s - loss: 0.0655 - acc: 0.5091 - val_loss: 0.0719 - val_acc: 0.4427\\nEpoch 11/40\\n20000/20000 [==============================] - 50s - loss: 0.0644 - acc: 0.5160 - val_loss: 0.0705 - val_acc: 0.4539\\nEpoch 12/40\\n20000/20000 [==============================] - 50s - loss: 0.0633 - acc: 0.5320 - val_loss: 0.0705 - val_acc: 0.4617\\nEpoch 13/40\\n20000/20000 [==============================] - 51s - loss: 0.0622 - acc: 0.5429 - val_loss: 0.0691 - val_acc: 0.4671\\nEpoch 14/40\\n20000/20000 [==============================] - 52s - loss: 0.0612 - acc: 0.5570 - val_loss: 0.0722 - val_acc: 0.4412\\nEpoch 15/40\\n20000/20000 [==============================] - 52s - loss: 0.0601 - acc: 0.5664 - val_loss: 0.0687 - val_acc: 0.4744\\nEpoch 16/40\\n20000/20000 [==============================] - 53s - loss: 0.0592 - acc: 0.5792 - val_loss: 0.0693 - val_acc: 0.4810\\nEpoch 17/40\\n20000/20000 [==============================] - 53s - loss: 0.0579 - acc: 0.5904 - val_loss: 0.0709 - val_acc: 0.4693\\nEpoch 18/40\\n20000/20000 [==============================] - 54s - loss: 0.0570 - acc: 0.6039 - val_loss: 0.0683 - val_acc: 0.4873\\nEpoch 19/40\\n20000/20000 [==============================] - 54s - loss: 0.0559 - acc: 0.6155 - val_loss: 0.0690 - val_acc: 0.4788\\nEpoch 20/40\\n20000/20000 [==============================] - 55s - loss: 0.0548 - acc: 0.6240 - val_loss: 0.0689 - val_acc: 0.4866\\nEpoch 21/40\\n20000/20000 [==============================] - 55s - loss: 0.0538 - acc: 0.6347 - val_loss: 0.0683 - val_acc: 0.4930\\nEpoch 22/40\\n20000/20000 [==============================] - 54s - loss: 0.0530 - acc: 0.6450 - val_loss: 0.0678 - val_acc: 0.4987\\nEpoch 23/40\\n20000/20000 [==============================] - 54s - loss: 0.0519 - acc: 0.6539 - val_loss: 0.0694 - val_acc: 0.4843\\nEpoch 24/40\\n20000/20000 [==============================] - 54s - loss: 0.0508 - acc: 0.6665 - val_loss: 0.0694 - val_acc: 0.4840\\nEpoch 25/40\\n20000/20000 [==============================] - 55s - loss: 0.0501 - acc: 0.6760 - val_loss: 0.0679 - val_acc: 0.4967\\nEpoch 26/40\\n20000/20000 [==============================] - 54s - loss: 0.0492 - acc: 0.6837 - val_loss: 0.0694 - val_acc: 0.4949\\nEpoch 27/40\\n20000/20000 [==============================] - 55s - loss: 0.0482 - acc: 0.6943 - val_loss: 0.0726 - val_acc: 0.4732\\nEpoch 28/40\\n20000/20000 [==============================] - 56s - loss: 0.0474 - acc: 0.7018 - val_loss: 0.0691 - val_acc: 0.4939\\nEpoch 29/40\\n20000/20000 [==============================] - 55s - loss: 0.0462 - acc: 0.7147 - val_loss: 0.0736 - val_acc: 0.4677\\nEpoch 30/40\\n20000/20000 [==============================] - 55s - loss: 0.0455 - acc: 0.7203 - val_loss: 0.0700 - val_acc: 0.4892\\nEpoch 31/40\\n20000/20000 [==============================] - 56s - loss: 0.0447 - acc: 0.7285 - val_loss: 0.0707 - val_acc: 0.4880\\nEpoch 32/40\\n20000/20000 [==============================] - 56s - loss: 0.0438 - acc: 0.7380 - val_loss: 0.0689 - val_acc: 0.4976\\nEpoch 33/40\\n20000/20000 [==============================] - 55s - loss: 0.0430 - acc: 0.7423 - val_loss: 0.0699 - val_acc: 0.5008\\nEpoch 34/40\\n20000/20000 [==============================] - 56s - loss: 0.0421 - acc: 0.7541 - val_loss: 0.0698 - val_acc: 0.4975\\nEpoch 35/40\\n20000/20000 [==============================] - 56s - loss: 0.0414 - acc: 0.7607 - val_loss: 0.0715 - val_acc: 0.4851\\nEpoch 36/40\\n20000/20000 [==============================] - 54s - loss: 0.0405 - acc: 0.7671 - val_loss: 0.0706 - val_acc: 0.4997\\nEpoch 37/40\\n20000/20000 [==============================] - 54s - loss: 0.0397 - acc: 0.7767 - val_loss: 0.0698 - val_acc: 0.4977\\nEpoch 38/40\\n20000/20000 [==============================] - 55s - loss: 0.0389 - acc: 0.7837 - val_loss: 0.0712 - val_acc: 0.4949\\nEpoch 39/40\\n20000/20000 [==============================] - 55s - loss: 0.0381 - acc: 0.7914 - val_loss: 0.0711 - val_acc: 0.4972\\nEpoch 40/40\\n20000/20000 [==============================] - 55s - loss: 0.0375 - acc: 0.7974 - val_loss: 0.0737 - val_acc: 0.4849\\n ========================== \\nthe smallest weight is =  -0.236733\\nthe biggest weight is =  0.400485\\nthe most mainstream order is as follow\\n[(1.00E+02, 3624), (1.00E+01, 639), (1.00E+03, 533), (1.00E+04, 46), (1.00E+05, 4), (1.00E+07, 1), (1.00E+06, 1)]\\n ========================== \\nthe reg is at  =  0.01\\n(The weight is init at l1 = , array(0.0, dtype=float32),  l2 = , array(0.009999999776482582, dtype=float32))\\n(param = , dense_15_W)\\n(The reg_loss is called, Elemwise{add,no_inplace}.0)\\nTrain on 20000 samples, validate on 10000 samples\\nEpoch 1/40\\n20000/20000 [==============================] - 37s - loss: 0.0994 - acc: 0.2470 - val_loss: 0.0816 - val_acc: 0.3185\\nEpoch 2/40\\n20000/20000 [==============================] - 37s - loss: 0.0797 - acc: 0.3437 - val_loss: 0.0779 - val_acc: 0.3632\\nEpoch 3/40\\n20000/20000 [==============================] - 38s - loss: 0.0761 - acc: 0.3856 - val_loss: 0.0750 - val_acc: 0.3962\\nEpoch 4/40\\n20000/20000 [==============================] - 41s - loss: 0.0739 - acc: 0.4108 - val_loss: 0.0733 - val_acc: 0.4190\\nEpoch 5/40\\n20000/20000 [==============================] - 44s - loss: 0.0722 - acc: 0.4359 - val_loss: 0.0723 - val_acc: 0.4344\\nEpoch 6/40\\n20000/20000 [==============================] - 46s - loss: 0.0705 - acc: 0.4500 - val_loss: 0.0730 - val_acc: 0.4210\\nEpoch 7/40\\n20000/20000 [==============================] - 49s - loss: 0.0692 - acc: 0.4669 - val_loss: 0.0701 - val_acc: 0.4476\\nEpoch 8/40\\n20000/20000 [==============================] - 51s - loss: 0.0680 - acc: 0.4820 - val_loss: 0.0720 - val_acc: 0.4396\\nEpoch 9/40\\n20000/20000 [==============================] - 52s - loss: 0.0667 - acc: 0.4932 - val_loss: 0.0701 - val_acc: 0.4592\\nEpoch 10/40\\n20000/20000 [==============================] - 53s - loss: 0.0657 - acc: 0.5006 - val_loss: 0.0697 - val_acc: 0.4662\\nEpoch 11/40\\n20000/20000 [==============================] - 54s - loss: 0.0644 - acc: 0.5170 - val_loss: 0.0706 - val_acc: 0.4668\\nEpoch 12/40\\n20000/20000 [==============================] - 54s - loss: 0.0634 - acc: 0.5326 - val_loss: 0.0696 - val_acc: 0.4614\\nEpoch 13/40\\n20000/20000 [==============================] - 55s - loss: 0.0622 - acc: 0.5415 - val_loss: 0.0691 - val_acc: 0.4711\\nEpoch 14/40\\n20000/20000 [==============================] - 56s - loss: 0.0612 - acc: 0.5518 - val_loss: 0.0710 - val_acc: 0.4571\\nEpoch 15/40\\n20000/20000 [==============================] - 56s - loss: 0.0601 - acc: 0.5653 - val_loss: 0.0705 - val_acc: 0.4644\\nEpoch 16/40\\n20000/20000 [==============================] - 56s - loss: 0.0592 - acc: 0.5751 - val_loss: 0.0691 - val_acc: 0.4773\\nEpoch 17/40\\n20000/20000 [==============================] - 56s - loss: 0.0581 - acc: 0.5859 - val_loss: 0.0688 - val_acc: 0.4782\\nEpoch 18/40\\n20000/20000 [==============================] - 56s - loss: 0.0572 - acc: 0.5965 - val_loss: 0.0685 - val_acc: 0.4788\\nEpoch 19/40\\n20000/20000 [==============================] - 57s - loss: 0.0563 - acc: 0.6040 - val_loss: 0.0675 - val_acc: 0.4907\\nEpoch 20/40\\n20000/20000 [==============================] - 57s - loss: 0.0552 - acc: 0.6191 - val_loss: 0.0698 - val_acc: 0.4800\\nEpoch 21/40\\n20000/20000 [==============================] - 58s - loss: 0.0543 - acc: 0.6280 - val_loss: 0.0735 - val_acc: 0.4440\\nEpoch 22/40\\n20000/20000 [==============================] - 58s - loss: 0.0533 - acc: 0.6398 - val_loss: 0.0700 - val_acc: 0.4727\\nEpoch 23/40\\n20000/20000 [==============================] - 57s - loss: 0.0525 - acc: 0.6491 - val_loss: 0.0697 - val_acc: 0.4787\\nEpoch 24/40\\n20000/20000 [==============================] - 58s - loss: 0.0515 - acc: 0.6571 - val_loss: 0.0700 - val_acc: 0.4857\\nEpoch 25/40\\n20000/20000 [==============================] - 58s - loss: 0.0506 - acc: 0.6646 - val_loss: 0.0686 - val_acc: 0.4885\\nEpoch 26/40\\n20000/20000 [==============================] - 58s - loss: 0.0498 - acc: 0.6739 - val_loss: 0.0696 - val_acc: 0.4886\\nEpoch 27/40\\n20000/20000 [==============================] - 59s - loss: 0.0487 - acc: 0.6864 - val_loss: 0.0705 - val_acc: 0.4771\\nEpoch 28/40\\n20000/20000 [==============================] - 59s - loss: 0.0478 - acc: 0.6944 - val_loss: 0.0685 - val_acc: 0.4997\\nEpoch 29/40\\n20000/20000 [==============================] - 58s - loss: 0.0472 - acc: 0.7028 - val_loss: 0.0702 - val_acc: 0.4918\\nEpoch 30/40\\n20000/20000 [==============================] - 59s - loss: 0.0462 - acc: 0.7114 - val_loss: 0.0700 - val_acc: 0.4897\\nEpoch 31/40\\n20000/20000 [==============================] - 60s - loss: 0.0454 - acc: 0.7201 - val_loss: 0.0755 - val_acc: 0.4578\\nEpoch 32/40\\n20000/20000 [==============================] - 59s - loss: 0.0445 - acc: 0.7282 - val_loss: 0.0713 - val_acc: 0.4758\\nEpoch 33/40\\n20000/20000 [==============================] - 60s - loss: 0.0438 - acc: 0.7370 - val_loss: 0.0696 - val_acc: 0.4935\\nEpoch 34/40\\n20000/20000 [==============================] - 60s - loss: 0.0429 - acc: 0.7502 - val_loss: 0.0713 - val_acc: 0.4918\\nEpoch 35/40\\n20000/20000 [==============================] - 61s - loss: 0.0421 - acc: 0.7550 - val_loss: 0.0709 - val_acc: 0.4904\\nEpoch 36/40\\n20000/20000 [==============================] - 61s - loss: 0.0415 - acc: 0.7610 - val_loss: 0.0723 - val_acc: 0.4887\\nEpoch 37/40\\n20000/20000 [==============================] - 61s - loss: 0.0407 - acc: 0.7694 - val_loss: 0.0718 - val_acc: 0.4846\\nEpoch 38/40\\n20000/20000 [==============================] - 61s - loss: 0.0400 - acc: 0.7724 - val_loss: 0.0725 - val_acc: 0.4911\\nEpoch 39/40\\n20000/20000 [==============================] - 61s - loss: 0.0392 - acc: 0.7852 - val_loss: 0.0716 - val_acc: 0.4873\\nEpoch 40/40\\n20000/20000 [==============================] - 60s - loss: 0.0384 - acc: 0.7878 - val_loss: 0.0723 - val_acc: 0.4896\\n ========================== \\nthe smallest weight is =  -0.232917\\nthe biggest weight is =  0.374131\\nthe most mainstream order is as follow\\n[(1.00E+02, 3701), (1.00E+01, 621), (1.00E+03, 490), (1.00E+04, 47), (1.00E+05, 8)]\\n ========================== \\nthe reg is at  =  0.1\\n(The weight is init at l1 = , array(0.0, dtype=float32),  l2 = , array(0.10000000149011612, dtype=float32))\\n(param = , dense_18_W)\\n(The reg_loss is called, Elemwise{add,no_inplace}.0)\\nTrain on 20000 samples, validate on 10000 samples\\nEpoch 1/40\\n20000/20000 [==============================] - 39s - loss: 0.0971 - acc: 0.2452 - val_loss: 0.0813 - val_acc: 0.3145\\nEpoch 2/40\\n20000/20000 [==============================] - 38s - loss: 0.0800 - acc: 0.3440 - val_loss: 0.0756 - val_acc: 0.3981\\nEpoch 3/40\\n20000/20000 [==============================] - 39s - loss: 0.0768 - acc: 0.3858 - val_loss: 0.0774 - val_acc: 0.3646\\nEpoch 4/40\\n20000/20000 [==============================] - 43s - loss: 0.0743 - acc: 0.4129 - val_loss: 0.0742 - val_acc: 0.4138\\nEpoch 5/40\\n20000/20000 [==============================] - 46s - loss: 0.0723 - acc: 0.4349 - val_loss: 0.0732 - val_acc: 0.4101\\nEpoch 6/40\\n20000/20000 [==============================] - 47s - loss: 0.0707 - acc: 0.4533 - val_loss: 0.0730 - val_acc: 0.4257\\nEpoch 7/40\\n20000/20000 [==============================] - 48s - loss: 0.0693 - acc: 0.4681 - val_loss: 0.0712 - val_acc: 0.4428\\nEpoch 8/40\\n20000/20000 [==============================] - 49s - loss: 0.0682 - acc: 0.4753 - val_loss: 0.0701 - val_acc: 0.4520\\nEpoch 9/40\\n20000/20000 [==============================] - 51s - loss: 0.0669 - acc: 0.4922 - val_loss: 0.0705 - val_acc: 0.4510\\nEpoch 10/40\\n20000/20000 [==============================] - 51s - loss: 0.0656 - acc: 0.5077 - val_loss: 0.0725 - val_acc: 0.4285\\nEpoch 11/40\\n20000/20000 [==============================] - 51s - loss: 0.0645 - acc: 0.5200 - val_loss: 0.0710 - val_acc: 0.4544\\nEpoch 12/40\\n20000/20000 [==============================] - 51s - loss: 0.0636 - acc: 0.5276 - val_loss: 0.0709 - val_acc: 0.4412\\nEpoch 13/40\\n20000/20000 [==============================] - 52s - loss: 0.0625 - acc: 0.5428 - val_loss: 0.0690 - val_acc: 0.4736\\nEpoch 14/40\\n20000/20000 [==============================] - 53s - loss: 0.0614 - acc: 0.5516 - val_loss: 0.0697 - val_acc: 0.4661\\nEpoch 15/40\\n20000/20000 [==============================] - 52s - loss: 0.0604 - acc: 0.5675 - val_loss: 0.0682 - val_acc: 0.4788\\nEpoch 16/40\\n20000/20000 [==============================] - 53s - loss: 0.0594 - acc: 0.5754 - val_loss: 0.0679 - val_acc: 0.4841\\nEpoch 17/40\\n20000/20000 [==============================] - 53s - loss: 0.0583 - acc: 0.5884 - val_loss: 0.0690 - val_acc: 0.4725\\nEpoch 18/40\\n20000/20000 [==============================] - 54s - loss: 0.0574 - acc: 0.5973 - val_loss: 0.0689 - val_acc: 0.4747\\nEpoch 19/40\\n20000/20000 [==============================] - 54s - loss: 0.0563 - acc: 0.6114 - val_loss: 0.0694 - val_acc: 0.4735\\nEpoch 20/40\\n20000/20000 [==============================] - 54s - loss: 0.0553 - acc: 0.6199 - val_loss: 0.0715 - val_acc: 0.4540\\nEpoch 21/40\\n20000/20000 [==============================] - 55s - loss: 0.0544 - acc: 0.6306 - val_loss: 0.0708 - val_acc: 0.4723\\nEpoch 22/40\\n20000/20000 [==============================] - 55s - loss: 0.0535 - acc: 0.6399 - val_loss: 0.0693 - val_acc: 0.4826\\nEpoch 23/40\\n20000/20000 [==============================] - 54s - loss: 0.0526 - acc: 0.6467 - val_loss: 0.0696 - val_acc: 0.4751\\nEpoch 24/40\\n20000/20000 [==============================] - 54s - loss: 0.0515 - acc: 0.6616 - val_loss: 0.0690 - val_acc: 0.4881\\nEpoch 25/40\\n20000/20000 [==============================] - 53s - loss: 0.0506 - acc: 0.6689 - val_loss: 0.0709 - val_acc: 0.4760\\nEpoch 26/40\\n20000/20000 [==============================] - 54s - loss: 0.0500 - acc: 0.6742 - val_loss: 0.0686 - val_acc: 0.4885\\nEpoch 27/40\\n20000/20000 [==============================] - 54s - loss: 0.0488 - acc: 0.6857 - val_loss: 0.0694 - val_acc: 0.4853\\nEpoch 28/40\\n20000/20000 [==============================] - 54s - loss: 0.0479 - acc: 0.6931 - val_loss: 0.0713 - val_acc: 0.4824\\nEpoch 29/40\\n20000/20000 [==============================] - 55s - loss: 0.0471 - acc: 0.7052 - val_loss: 0.0685 - val_acc: 0.4948\\nEpoch 30/40\\n20000/20000 [==============================] - 54s - loss: 0.0462 - acc: 0.7140 - val_loss: 0.0698 - val_acc: 0.4867\\nEpoch 31/40\\n20000/20000 [==============================] - 54s - loss: 0.0454 - acc: 0.7199 - val_loss: 0.0704 - val_acc: 0.4925\\nEpoch 32/40\\n20000/20000 [==============================] - 55s - loss: 0.0445 - acc: 0.7309 - val_loss: 0.0706 - val_acc: 0.4870\\nEpoch 33/40\\n20000/20000 [==============================] - 55s - loss: 0.0437 - acc: 0.7384 - val_loss: 0.0719 - val_acc: 0.4846\\nEpoch 34/40\\n20000/20000 [==============================] - 56s - loss: 0.0429 - acc: 0.7465 - val_loss: 0.0708 - val_acc: 0.4878\\nEpoch 35/40\\n20000/20000 [==============================] - 56s - loss: 0.0422 - acc: 0.7545 - val_loss: 0.0718 - val_acc: 0.4854\\nEpoch 36/40\\n20000/20000 [==============================] - 56s - loss: 0.0414 - acc: 0.7617 - val_loss: 0.0716 - val_acc: 0.4882\\nEpoch 37/40\\n20000/20000 [==============================] - 56s - loss: 0.0407 - acc: 0.7676 - val_loss: 0.0695 - val_acc: 0.5008\\nEpoch 38/40\\n20000/20000 [==============================] - 57s - loss: 0.0398 - acc: 0.7781 - val_loss: 0.0709 - val_acc: 0.4893\\nEpoch 39/40\\n20000/20000 [==============================] - 56s - loss: 0.0391 - acc: 0.7869 - val_loss: 0.0726 - val_acc: 0.4814\\nEpoch 40/40\\n20000/20000 [==============================] - 58s - loss: 0.0383 - acc: 0.7913 - val_loss: 0.0700 - val_acc: 0.4939\\n ========================== \\nthe smallest weight is =  -0.232783\\nthe biggest weight is =  0.364979\\nthe most mainstream order is as follow\\n[(1.00E+02, 3666), (1.00E+03, 699), (1.00E+01, 449), (1.00E+04, 66), (1.00E+05, 4), (1.00E+06, 1)]\\n ========================== \\nthe reg is at  =  10\\n(The weight is init at l1 = , array(0.0, dtype=float32),  l2 = , array(10.0, dtype=float32))\\n(param = , dense_21_W)\\n(The reg_loss is called, Elemwise{add,no_inplace}.0)\\nTrain on 20000 samples, validate on 10000 samples\\nEpoch 1/40\\n20000/20000 [==============================] - 39s - loss: 0.1228 - acc: 0.2514 - val_loss: 0.0846 - val_acc: 0.2620\\nEpoch 2/40\\n20000/20000 [==============================] - 38s - loss: 0.0836 - acc: 0.3571 - val_loss: 0.0778 - val_acc: 0.3498\\nEpoch 3/40\\n20000/20000 [==============================] - 39s - loss: 0.0777 - acc: 0.3947 - val_loss: 0.0759 - val_acc: 0.3818\\nEpoch 4/40\\n20000/20000 [==============================] - 39s - loss: 0.0749 - acc: 0.4146 - val_loss: 0.0717 - val_acc: 0.4390\\nEpoch 5/40\\n20000/20000 [==============================] - 41s - loss: 0.0731 - acc: 0.4347 - val_loss: 0.0713 - val_acc: 0.4390\\nEpoch 6/40\\n20000/20000 [==============================] - 40s - loss: 0.0714 - acc: 0.4479 - val_loss: 0.0713 - val_acc: 0.4367\\nEpoch 7/40\\n20000/20000 [==============================] - 41s - loss: 0.0703 - acc: 0.4627 - val_loss: 0.0711 - val_acc: 0.4349\\nEpoch 8/40\\n20000/20000 [==============================] - 41s - loss: 0.0691 - acc: 0.4764 - val_loss: 0.0697 - val_acc: 0.4565\\nEpoch 9/40\\n20000/20000 [==============================] - 41s - loss: 0.0680 - acc: 0.4878 - val_loss: 0.0694 - val_acc: 0.4537\\nEpoch 10/40\\n20000/20000 [==============================] - 41s - loss: 0.0670 - acc: 0.4946 - val_loss: 0.0691 - val_acc: 0.4532\\nEpoch 11/40\\n20000/20000 [==============================] - 42s - loss: 0.0662 - acc: 0.5036 - val_loss: 0.0682 - val_acc: 0.4593\\nEpoch 12/40\\n20000/20000 [==============================] - 42s - loss: 0.0651 - acc: 0.5177 - val_loss: 0.0687 - val_acc: 0.4616\\nEpoch 13/40\\n20000/20000 [==============================] - 41s - loss: 0.0644 - acc: 0.5220 - val_loss: 0.0673 - val_acc: 0.4766\\nEpoch 14/40\\n20000/20000 [==============================] - 42s - loss: 0.0635 - acc: 0.5336 - val_loss: 0.0673 - val_acc: 0.4780\\nEpoch 15/40\\n20000/20000 [==============================] - 42s - loss: 0.0628 - acc: 0.5434 - val_loss: 0.0675 - val_acc: 0.4730\\nEpoch 16/40\\n20000/20000 [==============================] - 42s - loss: 0.0621 - acc: 0.5504 - val_loss: 0.0672 - val_acc: 0.4790\\nEpoch 17/40\\n20000/20000 [==============================] - 42s - loss: 0.0612 - acc: 0.5584 - val_loss: 0.0671 - val_acc: 0.4754\\nEpoch 18/40\\n20000/20000 [==============================] - 43s - loss: 0.0605 - acc: 0.5680 - val_loss: 0.0667 - val_acc: 0.4783\\nEpoch 19/40\\n20000/20000 [==============================] - 44s - loss: 0.0597 - acc: 0.5752 - val_loss: 0.0654 - val_acc: 0.4948\\nEpoch 20/40\\n20000/20000 [==============================] - 44s - loss: 0.0590 - acc: 0.5811 - val_loss: 0.0672 - val_acc: 0.4844\\nEpoch 21/40\\n20000/20000 [==============================] - 44s - loss: 0.0583 - acc: 0.5898 - val_loss: 0.0660 - val_acc: 0.4881\\nEpoch 22/40\\n20000/20000 [==============================] - 44s - loss: 0.0576 - acc: 0.5968 - val_loss: 0.0662 - val_acc: 0.4894\\nEpoch 23/40\\n20000/20000 [==============================] - 45s - loss: 0.0567 - acc: 0.6076 - val_loss: 0.0668 - val_acc: 0.4853\\nEpoch 24/40\\n20000/20000 [==============================] - 45s - loss: 0.0561 - acc: 0.6119 - val_loss: 0.0669 - val_acc: 0.4847\\nEpoch 25/40\\n20000/20000 [==============================] - 45s - loss: 0.0554 - acc: 0.6170 - val_loss: 0.0657 - val_acc: 0.4995\\nEpoch 26/40\\n20000/20000 [==============================] - 45s - loss: 0.0546 - acc: 0.6309 - val_loss: 0.0654 - val_acc: 0.5078\\nEpoch 27/40\\n20000/20000 [==============================] - 45s - loss: 0.0540 - acc: 0.6347 - val_loss: 0.0654 - val_acc: 0.5052\\nEpoch 28/40\\n20000/20000 [==============================] - 45s - loss: 0.0533 - acc: 0.6416 - val_loss: 0.0655 - val_acc: 0.5027\\nEpoch 29/40\\n20000/20000 [==============================] - 45s - loss: 0.0527 - acc: 0.6515 - val_loss: 0.0671 - val_acc: 0.4935\\nEpoch 30/40\\n20000/20000 [==============================] - 45s - loss: 0.0519 - acc: 0.6590 - val_loss: 0.0660 - val_acc: 0.4997\\nEpoch 31/40\\n20000/20000 [==============================] - 45s - loss: 0.0512 - acc: 0.6653 - val_loss: 0.0656 - val_acc: 0.5062\\nEpoch 32/40\\n20000/20000 [==============================] - 45s - loss: 0.0505 - acc: 0.6731 - val_loss: 0.0671 - val_acc: 0.4939\\nEpoch 33/40\\n20000/20000 [==============================] - 45s - loss: 0.0498 - acc: 0.6790 - val_loss: 0.0655 - val_acc: 0.5060\\nEpoch 34/40\\n20000/20000 [==============================] - 45s - loss: 0.0492 - acc: 0.6881 - val_loss: 0.0667 - val_acc: 0.4997\\nEpoch 35/40\\n20000/20000 [==============================] - 45s - loss: 0.0484 - acc: 0.6949 - val_loss: 0.0661 - val_acc: 0.5060\\nEpoch 36/40\\n20000/20000 [==============================] - 46s - loss: 0.0476 - acc: 0.7031 - val_loss: 0.0662 - val_acc: 0.5059\\nEpoch 37/40\\n20000/20000 [==============================] - 46s - loss: 0.0471 - acc: 0.7062 - val_loss: 0.0652 - val_acc: 0.5156\\nEpoch 38/40\\n20000/20000 [==============================] - 45s - loss: 0.0466 - acc: 0.7113 - val_loss: 0.0662 - val_acc: 0.5129\\nEpoch 39/40\\n20000/20000 [==============================] - 45s - loss: 0.0457 - acc: 0.7177 - val_loss: 0.0667 - val_acc: 0.5086\\nEpoch 40/40\\n20000/20000 [==============================] - 45s - loss: 0.0452 - acc: 0.7273 - val_loss: 0.0685 - val_acc: 0.4909\\n ========================== \\nthe smallest weight is =  -0.0552853\\nthe biggest weight is =  0.12153\\nthe most mainstream order is as follow\\n[(1.00E+03, 2814), (1.00E+02, 1444), (1.00E+04, 502), (1.00E+05, 76), (1.00E+01, 7), (1.00E+06, 2)]\\n ========================== \\nthe reg is at  =  100\\n(The weight is init at l1 = , array(0.0, dtype=float32),  l2 = , array(100.0, dtype=float32))\\n(param = , dense_24_W)\\n(The reg_loss is called, Elemwise{add,no_inplace}.0)\\nTrain on 20000 samples, validate on 10000 samples\\nEpoch 1/40\\n20000/20000 [==============================] - 37s - loss: 0.2133 - acc: 0.2603 - val_loss: 0.0798 - val_acc: 0.3621\\nEpoch 2/40\\n20000/20000 [==============================] - 37s - loss: 0.0819 - acc: 0.3544 - val_loss: 0.0770 - val_acc: 0.3895\\nEpoch 3/40\\n20000/20000 [==============================] - 38s - loss: 0.0782 - acc: 0.3848 - val_loss: 0.0759 - val_acc: 0.3781\\nEpoch 4/40\\n20000/20000 [==============================] - 38s - loss: 0.0764 - acc: 0.4005 - val_loss: 0.0742 - val_acc: 0.4109\\nEpoch 5/40\\n20000/20000 [==============================] - 38s - loss: 0.0750 - acc: 0.4176 - val_loss: 0.0745 - val_acc: 0.3935\\nEpoch 6/40\\n20000/20000 [==============================] - 38s - loss: 0.0737 - acc: 0.4309 - val_loss: 0.0719 - val_acc: 0.4284\\nEpoch 7/40\\n20000/20000 [==============================] - 38s - loss: 0.0728 - acc: 0.4457 - val_loss: 0.0720 - val_acc: 0.4278\\nEpoch 8/40\\n20000/20000 [==============================] - 37s - loss: 0.0718 - acc: 0.4536 - val_loss: 0.0720 - val_acc: 0.4196\\nEpoch 9/40\\n20000/20000 [==============================] - 38s - loss: 0.0710 - acc: 0.4615 - val_loss: 0.0704 - val_acc: 0.4444\\nEpoch 10/40\\n20000/20000 [==============================] - 38s - loss: 0.0702 - acc: 0.4694 - val_loss: 0.0714 - val_acc: 0.4336\\nEpoch 11/40\\n20000/20000 [==============================] - 37s - loss: 0.0695 - acc: 0.4758 - val_loss: 0.0688 - val_acc: 0.4608\\nEpoch 12/40\\n20000/20000 [==============================] - 38s - loss: 0.0687 - acc: 0.4856 - val_loss: 0.0696 - val_acc: 0.4513\\nEpoch 13/40\\n20000/20000 [==============================] - 38s - loss: 0.0681 - acc: 0.4915 - val_loss: 0.0689 - val_acc: 0.4541\\nEpoch 14/40\\n20000/20000 [==============================] - 38s - loss: 0.0674 - acc: 0.4962 - val_loss: 0.0682 - val_acc: 0.4676\\nEpoch 15/40\\n20000/20000 [==============================] - 38s - loss: 0.0667 - acc: 0.5060 - val_loss: 0.0683 - val_acc: 0.4609\\nEpoch 16/40\\n20000/20000 [==============================] - 38s - loss: 0.0663 - acc: 0.5093 - val_loss: 0.0684 - val_acc: 0.4595\\nEpoch 17/40\\n20000/20000 [==============================] - 38s - loss: 0.0655 - acc: 0.5176 - val_loss: 0.0668 - val_acc: 0.4760\\nEpoch 18/40\\n20000/20000 [==============================] - 38s - loss: 0.0650 - acc: 0.5200 - val_loss: 0.0697 - val_acc: 0.4551\\nEpoch 19/40\\n20000/20000 [==============================] - 38s - loss: 0.0645 - acc: 0.5294 - val_loss: 0.0666 - val_acc: 0.4825\\nEpoch 20/40\\n20000/20000 [==============================] - 38s - loss: 0.0638 - acc: 0.5361 - val_loss: 0.0679 - val_acc: 0.4655\\nEpoch 21/40\\n20000/20000 [==============================] - 39s - loss: 0.0634 - acc: 0.5394 - val_loss: 0.0663 - val_acc: 0.4812\\nEpoch 22/40\\n20000/20000 [==============================] - 38s - loss: 0.0628 - acc: 0.5441 - val_loss: 0.0673 - val_acc: 0.4744\\nEpoch 23/40\\n20000/20000 [==============================] - 39s - loss: 0.0624 - acc: 0.5496 - val_loss: 0.0662 - val_acc: 0.4806\\nEpoch 24/40\\n20000/20000 [==============================] - 39s - loss: 0.0619 - acc: 0.5571 - val_loss: 0.0669 - val_acc: 0.4754\\nEpoch 25/40\\n20000/20000 [==============================] - 39s - loss: 0.0613 - acc: 0.5620 - val_loss: 0.0668 - val_acc: 0.4733\\nEpoch 26/40\\n20000/20000 [==============================] - 40s - loss: 0.0609 - acc: 0.5643 - val_loss: 0.0658 - val_acc: 0.4831\\nEpoch 27/40\\n20000/20000 [==============================] - 40s - loss: 0.0604 - acc: 0.5711 - val_loss: 0.0681 - val_acc: 0.4682\\nEpoch 28/40\\n20000/20000 [==============================] - 40s - loss: 0.0598 - acc: 0.5781 - val_loss: 0.0669 - val_acc: 0.4792\\nEpoch 29/40\\n20000/20000 [==============================] - 40s - loss: 0.0594 - acc: 0.5817 - val_loss: 0.0664 - val_acc: 0.4796\\nEpoch 30/40\\n20000/20000 [==============================] - 40s - loss: 0.0589 - acc: 0.5860 - val_loss: 0.0676 - val_acc: 0.4777\\nEpoch 31/40\\n20000/20000 [==============================] - 39s - loss: 0.0583 - acc: 0.5954 - val_loss: 0.0658 - val_acc: 0.4931\\nEpoch 32/40\\n20000/20000 [==============================] - 40s - loss: 0.0579 - acc: 0.5954 - val_loss: 0.0655 - val_acc: 0.4928\\nEpoch 33/40\\n20000/20000 [==============================] - 39s - loss: 0.0575 - acc: 0.6044 - val_loss: 0.0652 - val_acc: 0.4970\\nEpoch 34/40\\n20000/20000 [==============================] - 39s - loss: 0.0570 - acc: 0.6059 - val_loss: 0.0651 - val_acc: 0.4927\\nEpoch 35/40\\n20000/20000 [==============================] - 40s - loss: 0.0565 - acc: 0.6161 - val_loss: 0.0690 - val_acc: 0.4745\\nEpoch 36/40\\n20000/20000 [==============================] - 40s - loss: 0.0561 - acc: 0.6190 - val_loss: 0.0656 - val_acc: 0.4956\\nEpoch 37/40\\n20000/20000 [==============================] - 40s - loss: 0.0556 - acc: 0.6210 - val_loss: 0.0647 - val_acc: 0.4969\\nEpoch 38/40\\n20000/20000 [==============================] - 40s - loss: 0.0552 - acc: 0.6243 - val_loss: 0.0679 - val_acc: 0.4799\\nEpoch 39/40\\n20000/20000 [==============================] - 40s - loss: 0.0545 - acc: 0.6319 - val_loss: 0.0655 - val_acc: 0.4966\\nEpoch 40/40\\n20000/20000 [==============================] - 40s - loss: 0.0542 - acc: 0.6363 - val_loss: 0.0660 - val_acc: 0.4941\\n ========================== \\nthe smallest weight is =  -0.0205635\\nthe biggest weight is =  0.0490768\\nthe most mainstream order is as follow\\n[(1.00E+04, 2361), (1.00E+03, 1923), (1.00E+05, 357), (1.00E+02, 216), (1.00E+06, 49), (1.00E+07, 2)]\\n ========================== \\nthe reg is at  =  1000\\n(The weight is init at l1 = , array(0.0, dtype=float32),  l2 = , array(1000.0, dtype=float32))\\n(param = , dense_27_W)\\n(The reg_loss is called, Elemwise{add,no_inplace}.0)\\nTrain on 20000 samples, validate on 10000 samples\\nEpoch 1/40\\n20000/20000 [==============================] - 37s - loss: 0.7276 - acc: 0.2562 - val_loss: 0.0832 - val_acc: 0.3040\\nEpoch 2/40\\n20000/20000 [==============================] - 37s - loss: 0.0845 - acc: 0.2967 - val_loss: 0.0809 - val_acc: 0.3470\\nEpoch 3/40\\n20000/20000 [==============================] - 38s - loss: 0.0826 - acc: 0.3242 - val_loss: 0.0794 - val_acc: 0.3467\\nEpoch 4/40\\n20000/20000 [==============================] - 38s - loss: 0.0813 - acc: 0.3488 - val_loss: 0.0794 - val_acc: 0.3269\\nEpoch 5/40\\n20000/20000 [==============================] - 38s - loss: 0.0802 - acc: 0.3604 - val_loss: 0.0772 - val_acc: 0.3809\\nEpoch 6/40\\n20000/20000 [==============================] - 38s - loss: 0.0792 - acc: 0.3704 - val_loss: 0.0776 - val_acc: 0.3726\\nEpoch 7/40\\n20000/20000 [==============================] - 37s - loss: 0.0785 - acc: 0.3847 - val_loss: 0.0759 - val_acc: 0.3816\\nEpoch 8/40\\n20000/20000 [==============================] - 38s - loss: 0.0778 - acc: 0.3936 - val_loss: 0.0759 - val_acc: 0.3825\\nEpoch 9/40\\n20000/20000 [==============================] - 38s - loss: 0.0772 - acc: 0.3967 - val_loss: 0.0751 - val_acc: 0.3923\\nEpoch 10/40\\n20000/20000 [==============================] - 38s - loss: 0.0766 - acc: 0.4065 - val_loss: 0.0742 - val_acc: 0.4063\\nEpoch 11/40\\n20000/20000 [==============================] - 37s - loss: 0.0761 - acc: 0.4109 - val_loss: 0.0736 - val_acc: 0.4198\\nEpoch 12/40\\n20000/20000 [==============================] - 37s - loss: 0.0756 - acc: 0.4183 - val_loss: 0.0735 - val_acc: 0.4134\\nEpoch 13/40\\n20000/20000 [==============================] - 37s - loss: 0.0750 - acc: 0.4259 - val_loss: 0.0735 - val_acc: 0.4200\\nEpoch 14/40\\n20000/20000 [==============================] - 37s - loss: 0.0746 - acc: 0.4316 - val_loss: 0.0727 - val_acc: 0.4209\\nEpoch 15/40\\n20000/20000 [==============================] - 37s - loss: 0.0742 - acc: 0.4361 - val_loss: 0.0723 - val_acc: 0.4362\\nEpoch 16/40\\n20000/20000 [==============================] - 37s - loss: 0.0737 - acc: 0.4414 - val_loss: 0.0730 - val_acc: 0.4172\\nEpoch 17/40\\n20000/20000 [==============================] - 37s - loss: 0.0733 - acc: 0.4490 - val_loss: 0.0725 - val_acc: 0.4254\\nEpoch 18/40\\n20000/20000 [==============================] - 38s - loss: 0.0728 - acc: 0.4522 - val_loss: 0.0716 - val_acc: 0.4343\\nEpoch 19/40\\n20000/20000 [==============================] - 38s - loss: 0.0724 - acc: 0.4583 - val_loss: 0.0716 - val_acc: 0.4346\\nEpoch 20/40\\n20000/20000 [==============================] - 38s - loss: 0.0720 - acc: 0.4610 - val_loss: 0.0704 - val_acc: 0.4463\\nEpoch 21/40\\n20000/20000 [==============================] - 38s - loss: 0.0715 - acc: 0.4685 - val_loss: 0.0720 - val_acc: 0.4266\\nEpoch 22/40\\n20000/20000 [==============================] - 37s - loss: 0.0713 - acc: 0.4694 - val_loss: 0.0702 - val_acc: 0.4425\\nEpoch 23/40\\n20000/20000 [==============================] - 37s - loss: 0.0709 - acc: 0.4746 - val_loss: 0.0703 - val_acc: 0.4403\\nEpoch 24/40\\n20000/20000 [==============================] - 38s - loss: 0.0706 - acc: 0.4782 - val_loss: 0.0704 - val_acc: 0.4469\\nEpoch 25/40\\n20000/20000 [==============================] - 37s - loss: 0.0701 - acc: 0.4805 - val_loss: 0.0702 - val_acc: 0.4349\\nEpoch 26/40\\n20000/20000 [==============================] - 37s - loss: 0.0698 - acc: 0.4866 - val_loss: 0.0691 - val_acc: 0.4599\\nEpoch 27/40\\n20000/20000 [==============================] - 38s - loss: 0.0695 - acc: 0.4923 - val_loss: 0.0701 - val_acc: 0.4534\\nEpoch 28/40\\n20000/20000 [==============================] - 37s - loss: 0.0692 - acc: 0.4950 - val_loss: 0.0697 - val_acc: 0.4498\\nEpoch 29/40\\n20000/20000 [==============================] - 38s - loss: 0.0689 - acc: 0.4956 - val_loss: 0.0688 - val_acc: 0.4542\\nEpoch 30/40\\n20000/20000 [==============================] - 39s - loss: 0.0685 - acc: 0.5007 - val_loss: 0.0684 - val_acc: 0.4620\\nEpoch 31/40\\n20000/20000 [==============================] - 39s - loss: 0.0682 - acc: 0.5047 - val_loss: 0.0686 - val_acc: 0.4657\\nEpoch 32/40\\n20000/20000 [==============================] - 39s - loss: 0.0679 - acc: 0.5053 - val_loss: 0.0701 - val_acc: 0.4440\\nEpoch 33/40\\n20000/20000 [==============================] - 39s - loss: 0.0676 - acc: 0.5119 - val_loss: 0.0682 - val_acc: 0.4670\\nEpoch 34/40\\n20000/20000 [==============================] - 39s - loss: 0.0673 - acc: 0.5106 - val_loss: 0.0681 - val_acc: 0.4699\\nEpoch 35/40\\n20000/20000 [==============================] - 39s - loss: 0.0669 - acc: 0.5160 - val_loss: 0.0680 - val_acc: 0.4685\\nEpoch 36/40\\n20000/20000 [==============================] - 39s - loss: 0.0667 - acc: 0.5181 - val_loss: 0.0694 - val_acc: 0.4555\\nEpoch 37/40\\n20000/20000 [==============================] - 38s - loss: 0.0663 - acc: 0.5253 - val_loss: 0.0670 - val_acc: 0.4796\\nEpoch 38/40\\n20000/20000 [==============================] - 39s - loss: 0.0660 - acc: 0.5281 - val_loss: 0.0671 - val_acc: 0.4788\\nEpoch 39/40\\n20000/20000 [==============================] - 39s - loss: 0.0658 - acc: 0.5272 - val_loss: 0.0677 - val_acc: 0.4741\\nEpoch 40/40\\n20000/20000 [==============================] - 40s - loss: 0.0654 - acc: 0.5326 - val_loss: 0.0699 - val_acc: 0.4491\\n ========================== \\nthe smallest weight is =  -0.00762868\\nthe biggest weight is =  0.0239032\\nthe most mainstream order is as follow\\n[(1.00E+04, 2450), (1.00E+05, 1281), (1.00E+03, 669), (1.00E+06, 314), (1.00E+07, 69), (1.00E+10, 35), (1.00E+02, 30), (1.00E+08, 22), (1.00E+11, 15), (1.00E+09, 4), (1.00E+12, 1)]\\n ========================== \\nthe reg is at  =  10000\\n(The weight is init at l1 = , array(0.0, dtype=float32),  l2 = , array(10000.0, dtype=float32))\\n(param = , dense_30_W)\\n(The reg_loss is called, Elemwise{add,no_inplace}.0)\\nTrain on 20000 samples, validate on 10000 samples\\nEpoch 1/40\\n20000/20000 [==============================] - 38s - loss: 4.9401 - acc: 0.2157 - val_loss: 0.0872 - val_acc: 0.2064\\nEpoch 2/40\\n20000/20000 [==============================] - 39s - loss: 0.0916 - acc: 0.1970 - val_loss: 0.0855 - val_acc: 0.2158\\nEpoch 3/40\\n20000/20000 [==============================] - 40s - loss: 0.0930 - acc: 0.2109 - val_loss: 0.0851 - val_acc: 0.2283\\nEpoch 4/40\\n20000/20000 [==============================] - 41s - loss: 0.0945 - acc: 0.2320 - val_loss: 0.0842 - val_acc: 0.2664\\nEpoch 5/40\\n20000/20000 [==============================] - 41s - loss: 0.0961 - acc: 0.2415 - val_loss: 0.0834 - val_acc: 0.2651\\nEpoch 6/40\\n20000/20000 [==============================] - 39s - loss: 0.0978 - acc: 0.2552 - val_loss: 0.0832 - val_acc: 0.2671\\nEpoch 7/40\\n20000/20000 [==============================] - 39s - loss: 0.0996 - acc: 0.2637 - val_loss: 0.0833 - val_acc: 0.2620\\nEpoch 8/40\\n20000/20000 [==============================] - 39s - loss: 0.1013 - acc: 0.2698 - val_loss: 0.0825 - val_acc: 0.2910\\nEpoch 9/40\\n20000/20000 [==============================] - 39s - loss: 0.1029 - acc: 0.2792 - val_loss: 0.0827 - val_acc: 0.2934\\nEpoch 10/40\\n20000/20000 [==============================] - 40s - loss: 0.1045 - acc: 0.2857 - val_loss: 0.0817 - val_acc: 0.3040\\nEpoch 11/40\\n20000/20000 [==============================] - 39s - loss: 0.1061 - acc: 0.2956 - val_loss: 0.0817 - val_acc: 0.3203\\nEpoch 12/40\\n20000/20000 [==============================] - 39s - loss: 0.1075 - acc: 0.2988 - val_loss: 0.0811 - val_acc: 0.3050\\nEpoch 13/40\\n20000/20000 [==============================] - 40s - loss: 0.1089 - acc: 0.3026 - val_loss: 0.0812 - val_acc: 0.3015\\nEpoch 14/40\\n20000/20000 [==============================] - 40s - loss: 0.1104 - acc: 0.3085 - val_loss: 0.0812 - val_acc: 0.2999\\nEpoch 15/40\\n20000/20000 [==============================] - 39s - loss: 0.1118 - acc: 0.3160 - val_loss: 0.0805 - val_acc: 0.3106\\nEpoch 16/40\\n20000/20000 [==============================] - 40s - loss: 0.1133 - acc: 0.3203 - val_loss: 0.0802 - val_acc: 0.3329\\nEpoch 17/40\\n20000/20000 [==============================] - 40s - loss: 0.1148 - acc: 0.3284 - val_loss: 0.0798 - val_acc: 0.3258\\nEpoch 18/40\\n20000/20000 [==============================] - 39s - loss: 0.1159 - acc: 0.3281 - val_loss: 0.0794 - val_acc: 0.3441\\nEpoch 19/40\\n20000/20000 [==============================] - 40s - loss: 0.1168 - acc: 0.3347 - val_loss: 0.0792 - val_acc: 0.3403\\nEpoch 20/40\\n20000/20000 [==============================] - 40s - loss: 0.1177 - acc: 0.3382 - val_loss: 0.0791 - val_acc: 0.3340\\nEpoch 21/40\\n20000/20000 [==============================] - 40s - loss: 0.1191 - acc: 0.3448 - val_loss: 0.0794 - val_acc: 0.3392\\nEpoch 22/40\\n20000/20000 [==============================] - 40s - loss: 0.1205 - acc: 0.3482 - val_loss: 0.0786 - val_acc: 0.3470\\nEpoch 23/40\\n20000/20000 [==============================] - 39s - loss: 0.1218 - acc: 0.3524 - val_loss: 0.0782 - val_acc: 0.3565\\nEpoch 24/40\\n20000/20000 [==============================] - 39s - loss: 0.1230 - acc: 0.3530 - val_loss: 0.0786 - val_acc: 0.3404\\nEpoch 25/40\\n20000/20000 [==============================] - 39s - loss: 0.1243 - acc: 0.3605 - val_loss: 0.0781 - val_acc: 0.3507\\nEpoch 26/40\\n20000/20000 [==============================] - 39s - loss: 0.1257 - acc: 0.3605 - val_loss: 0.0780 - val_acc: 0.3482\\nEpoch 27/40\\n20000/20000 [==============================] - 40s - loss: 0.1273 - acc: 0.3616 - val_loss: 0.0782 - val_acc: 0.3569\\nEpoch 28/40\\n20000/20000 [==============================] - 39s - loss: 0.1288 - acc: 0.3654 - val_loss: 0.0780 - val_acc: 0.3588\\nEpoch 29/40\\n20000/20000 [==============================] - 39s - loss: 0.1302 - acc: 0.3684 - val_loss: 0.0775 - val_acc: 0.3749\\nEpoch 30/40\\n20000/20000 [==============================] - 40s - loss: 0.1317 - acc: 0.3693 - val_loss: 0.0769 - val_acc: 0.3720\\nEpoch 31/40\\n20000/20000 [==============================] - 39s - loss: 0.1330 - acc: 0.3713 - val_loss: 0.0772 - val_acc: 0.3735\\nEpoch 32/40\\n20000/20000 [==============================] - 38s - loss: 0.1342 - acc: 0.3734 - val_loss: 0.0770 - val_acc: 0.3607\\nEpoch 33/40\\n20000/20000 [==============================] - 40s - loss: 0.1356 - acc: 0.3760 - val_loss: 0.0771 - val_acc: 0.3695\\nEpoch 34/40\\n20000/20000 [==============================] - 40s - loss: 0.1370 - acc: 0.3780 - val_loss: 0.0766 - val_acc: 0.3817\\nEpoch 35/40\\n20000/20000 [==============================] - 39s - loss: 0.1381 - acc: 0.3815 - val_loss: 0.0762 - val_acc: 0.3738\\nEpoch 36/40\\n20000/20000 [==============================] - 39s - loss: 0.1394 - acc: 0.3822 - val_loss: 0.0758 - val_acc: 0.3896\\nEpoch 37/40\\n20000/20000 [==============================] - 39s - loss: 0.1406 - acc: 0.3849 - val_loss: 0.0759 - val_acc: 0.3893\\nEpoch 38/40\\n20000/20000 [==============================] - 39s - loss: 0.1418 - acc: 0.3876 - val_loss: 0.0758 - val_acc: 0.3913\\nEpoch 39/40\\n20000/20000 [==============================] - 38s - loss: 0.1429 - acc: 0.3922 - val_loss: 0.0760 - val_acc: 0.3828\\nEpoch 40/40\\n20000/20000 [==============================] - 38s - loss: 0.1443 - acc: 0.3947 - val_loss: 0.0752 - val_acc: 0.3926\\n ========================== \\nthe smallest weight is =  -0.00677686\\nthe biggest weight is =  0.00808495\\nthe most mainstream order is as follow\\n[(1.00E+04, 1706), (1.00E+05, 1390), (1.00E+03, 1233), (1.00E+06, 443), (1.00E+07, 105), (1.00E+08, 37), (1.00E+09, 20), (1.00E+10, 9), (1.00E+11, 6)]\\n ========================== \\nthe reg is at  =  100000\\n(The weight is init at l1 = , array(0.0, dtype=float32),  l2 = , array(100000.0, dtype=float32))\\n(param = , dense_33_W)\\n(The reg_loss is called, Elemwise{add,no_inplace}.0)\\nTrain on 20000 samples, validate on 10000 samples\\nEpoch 1/40\\n20000/20000 [==============================] - 37s - loss: 45.5950 - acc: 0.1911 - val_loss: 0.0911 - val_acc: 0.1212\\nEpoch 2/40\\n20000/20000 [==============================] - 37s - loss: 0.1682 - acc: 0.1293 - val_loss: 0.0899 - val_acc: 0.1345\\nEpoch 3/40\\n20000/20000 [==============================] - 40s - loss: 0.2531 - acc: 0.1449 - val_loss: 0.0893 - val_acc: 0.1539\\nEpoch 4/40\\n20000/20000 [==============================] - 40s - loss: 0.3394 - acc: 0.1575 - val_loss: 0.0880 - val_acc: 0.1649\\nEpoch 5/40\\n20000/20000 [==============================] - 41s - loss: 0.4280 - acc: 0.1619 - val_loss: 0.0877 - val_acc: 0.1663\\nEpoch 6/40\\n20000/20000 [==============================] - 41s - loss: 0.5209 - acc: 0.1619 - val_loss: 0.0878 - val_acc: 0.1659\\nEpoch 7/40\\n20000/20000 [==============================] - 41s - loss: 0.6141 - acc: 0.1680 - val_loss: 0.0870 - val_acc: 0.1654\\nEpoch 8/40\\n20000/20000 [==============================] - 41s - loss: 0.7156 - acc: 0.1676 - val_loss: 0.0872 - val_acc: 0.1625\\nEpoch 9/40\\n20000/20000 [==============================] - 41s - loss: 0.8242 - acc: 0.1698 - val_loss: 0.0874 - val_acc: 0.1658\\nEpoch 10/40\\n20000/20000 [==============================] - 41s - loss: 0.9419 - acc: 0.1757 - val_loss: 0.0868 - val_acc: 0.1718\\nEpoch 11/40\\n20000/20000 [==============================] - 41s - loss: 1.0629 - acc: 0.1738 - val_loss: 0.0863 - val_acc: 0.1723\\nEpoch 12/40\\n20000/20000 [==============================] - 42s - loss: 1.1895 - acc: 0.1792 - val_loss: 0.0865 - val_acc: 0.1919\\nEpoch 13/40\\n20000/20000 [==============================] - 43s - loss: 1.3188 - acc: 0.1770 - val_loss: 0.0864 - val_acc: 0.1813\\nEpoch 14/40\\n20000/20000 [==============================] - 43s - loss: 1.4477 - acc: 0.1787 - val_loss: 0.0869 - val_acc: 0.1654\\nEpoch 15/40\\n20000/20000 [==============================] - 43s - loss: 1.5783 - acc: 0.1791 - val_loss: 0.0862 - val_acc: 0.1719\\nEpoch 16/40\\n20000/20000 [==============================] - 45s - loss: 1.7106 - acc: 0.1794 - val_loss: 0.0865 - val_acc: 0.1642\\nEpoch 17/40\\n20000/20000 [==============================] - 45s - loss: 1.8439 - acc: 0.1834 - val_loss: 0.0865 - val_acc: 0.1861\\nEpoch 18/40\\n20000/20000 [==============================] - 45s - loss: 1.9794 - acc: 0.1831 - val_loss: 0.0864 - val_acc: 0.2000\\nEpoch 19/40\\n20000/20000 [==============================] - 45s - loss: 2.1162 - acc: 0.1847 - val_loss: 0.0860 - val_acc: 0.1864\\nEpoch 20/40\\n20000/20000 [==============================] - 45s - loss: 2.2532 - acc: 0.1872 - val_loss: 0.0861 - val_acc: 0.1756\\nEpoch 21/40\\n20000/20000 [==============================] - 45s - loss: 2.3884 - acc: 0.1856 - val_loss: 0.0860 - val_acc: 0.1648\\nEpoch 22/40\\n20000/20000 [==============================] - 45s - loss: 2.5246 - acc: 0.1845 - val_loss: 0.0859 - val_acc: 0.1781\\nEpoch 23/40\\n20000/20000 [==============================] - 46s - loss: 2.6629 - acc: 0.1839 - val_loss: 0.0856 - val_acc: 0.1887\\nEpoch 24/40\\n20000/20000 [==============================] - 47s - loss: 2.7996 - acc: 0.1843 - val_loss: 0.0866 - val_acc: 0.1776\\nEpoch 25/40\\n20000/20000 [==============================] - 48s - loss: 2.9376 - acc: 0.1855 - val_loss: 0.0857 - val_acc: 0.2086\\nEpoch 26/40\\n20000/20000 [==============================] - 48s - loss: 3.0774 - acc: 0.1890 - val_loss: 0.0861 - val_acc: 0.1748\\nEpoch 27/40\\n20000/20000 [==============================] - 49s - loss: 3.2167 - acc: 0.1898 - val_loss: 0.0858 - val_acc: 0.1881\\nEpoch 28/40\\n20000/20000 [==============================] - 48s - loss: 3.3561 - acc: 0.1951 - val_loss: 0.0861 - val_acc: 0.1793\\nEpoch 29/40\\n20000/20000 [==============================] - 48s - loss: 3.4955 - acc: 0.1924 - val_loss: 0.0860 - val_acc: 0.1654\\nEpoch 30/40\\n20000/20000 [==============================] - 47s - loss: 3.6343 - acc: 0.1959 - val_loss: 0.0858 - val_acc: 0.1930\\nEpoch 31/40\\n20000/20000 [==============================] - 47s - loss: 3.7736 - acc: 0.2010 - val_loss: 0.0852 - val_acc: 0.2089\\nEpoch 32/40\\n20000/20000 [==============================] - 48s - loss: 3.9135 - acc: 0.2061 - val_loss: 0.0854 - val_acc: 0.2154\\nEpoch 33/40\\n20000/20000 [==============================] - 48s - loss: 4.0544 - acc: 0.2125 - val_loss: 0.0861 - val_acc: 0.1849\\nEpoch 34/40\\n20000/20000 [==============================] - 49s - loss: 4.1952 - acc: 0.2170 - val_loss: 0.0862 - val_acc: 0.1796\\nEpoch 35/40\\n20000/20000 [==============================] - 49s - loss: 4.3352 - acc: 0.2183 - val_loss: 0.0845 - val_acc: 0.2251\\nEpoch 36/40\\n20000/20000 [==============================] - 48s - loss: 4.4749 - acc: 0.2206 - val_loss: 0.0847 - val_acc: 0.2332\\nEpoch 37/40\\n20000/20000 [==============================] - 49s - loss: 4.6163 - acc: 0.2249 - val_loss: 0.0842 - val_acc: 0.2353\\nEpoch 38/40\\n20000/20000 [==============================] - 48s - loss: 4.7575 - acc: 0.2260 - val_loss: 0.0847 - val_acc: 0.2150\\nEpoch 39/40\\n20000/20000 [==============================] - 48s - loss: 4.8999 - acc: 0.2332 - val_loss: 0.0841 - val_acc: 0.2330\\nEpoch 40/40\\n20000/20000 [==============================] - 48s - loss: 5.0429 - acc: 0.2301 - val_loss: 0.0842 - val_acc: 0.2357\\n ========================== \\nthe smallest weight is =  -0.00790428\\nthe biggest weight is =  0.0078959\\nthe most mainstream order is as follow\\n[(1.00E+03, 4757), (1.00E+04, 229), (1.00E+05, 68), (1.00E+06, 8), (1.00E+07, 1)]\\n ========================== \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.1874', '0.2516', '0.2944', '0.3684', '0.3414', '0.3721', '0.3894', '0.3632', '0.4114', '0.3890', '0.3542', '0.4119', '0.4078', '0.3970', '0.4074', '0.3686', '0.4254', '0.4235', '0.4158', '0.4102', '0.4194', '0.4340', '0.4288', '0.4397', '0.4410', '0.4348', '0.4357', '0.4331', '0.4293', '0.4457', '0.4104', '0.4420', '0.4387', '0.4315', '0.4310', '0.4486', '0.4493', '0.4285', '0.4068', '0.4114', '0.4224', '0.4427', '0.4384', '0.4162', '0.4548', '0.4233', '0.4539', '0.4351', '0.4041', '0.4597', '0.4457', '0.4131', '0.4331', '0.4517', '0.4325', '0.4388', '0.4425', '0.4523', '0.4470', '0.4441', '0.2393', '0.3076', '0.3625', '0.3545', '0.3450', '0.3488', '0.3976', '0.3877', '0.3614', '0.3956', '0.4159', '0.4125', '0.3854', '0.4085', '0.3820', '0.4213', '0.4155', '0.4192', '0.4252', '0.4241', '0.4401', '0.4290', '0.4387', '0.4167', '0.4177', '0.4139', '0.4407', '0.4263', '0.4385', '0.3967', '0.4239', '0.4519', '0.3803', '0.4478', '0.4363', '0.4230', '0.4466', '0.4407', '0.4427', '0.4508', '0.4337', '0.4182', '0.4623', '0.4537', '0.4266', '0.4513', '0.4161', '0.4305', '0.4556', '0.4311', '0.4255', '0.4425', '0.4446', '0.4096', '0.4429', '0.4307', '0.4486', '0.4548', '0.4395', '0.4507', '0.2004', '0.2979', '0.2939', '0.2769', '0.3015', '0.2776', '0.3316', '0.3378', '0.3538', '0.3451', '0.3493', '0.3547', '0.3623', '0.3583', '0.3652', '0.3703', '0.3583', '0.3754', '0.3751', '0.3797', '0.3689', '0.4026', '0.3909', '0.3751', '0.4065', '0.4020', '0.4090', '0.4094', '0.4124', '0.4060', '0.4129', '0.3997', '0.4114', '0.4079', '0.4110', '0.4046', '0.4149', '0.4084', '0.4120', '0.4073', '0.4036', '0.4099', '0.4136', '0.4109', '0.4333', '0.4228', '0.4186', '0.4187', '0.4296', '0.4330', '0.4230', '0.4157', '0.4244', '0.4394', '0.4305', '0.4298', '0.4293', '0.4272', '0.4078', '0.4361', '0.2582', '0.1884', '0.1592', '0.1900', '0.1899', '0.2396', '0.2049', '0.2602', '0.2348', '0.2102', '0.2560', '0.2371', '0.2260', '0.2553', '0.2616', '0.2870', '0.2677', '0.2848', '0.2443', '0.2515', '0.2594', '0.2767', '0.2707', '0.2686', '0.3084', '0.2978', '0.2880', '0.2944', '0.3111', '0.2864', '0.2828', '0.2944', '0.3076', '0.3086', '0.2953', '0.2917', '0.3304', '0.2868', '0.3160', '0.2986', '0.3440', '0.3043', '0.2934', '0.3121', '0.3205', '0.3190', '0.3208', '0.3217', '0.3336', '0.3261', '0.2999', '0.3214', '0.3187', '0.3459', '0.3426', '0.3558', '0.3464', '0.3472', '0.3519', '0.3419', '0.2480', '0.1000', '0.1592', '0.1044', '0.1672', '0.1533', '0.1575', '0.1090', '0.1671', '0.1527', '0.1392', '0.1709', '0.1669', '0.1501', '0.1545', '0.1490', '0.1527', '0.1681', '0.1772', '0.1665', '0.1689', '0.1677', '0.1684', '0.1780', '0.1686', '0.1784', '0.1833', '0.1684', '0.1622', '0.1761', '0.1891', '0.1777', '0.1787', '0.1923', '0.1694', '0.1714', '0.1754', '0.1693', '0.1943', '0.1817', '0.1859', '0.1679', '0.1773', '0.1808', '0.1839', '0.1816', '0.1735', '0.1763', '0.1755', '0.1791', '0.1721', '0.1801', '0.1839', '0.1883', '0.1868', '0.2252', '0.1730', '0.1883', '0.1691', '0.1817']\n",
      "['0.1963', '0.2723', '0.3301', '0.3644', '0.3890', '0.4096', '0.4260', '0.4421', '0.4537', '0.4747', '0.4786', '0.4959', '0.5084', '0.5094', '0.5259', '0.5286', '0.5496', '0.5504', '0.5624', '0.5827', '0.5930', '0.5977', '0.6099', '0.6196', '0.6304', '0.6361', '0.6494', '0.6554', '0.6739', '0.6783', '0.6841', '0.6930', '0.7041', '0.7144', '0.7243', '0.7339', '0.7410', '0.7543', '0.7523', '0.7656', '0.7750', '0.7791', '0.7813', '0.7956', '0.8026', '0.8121', '0.8126', '0.8187', '0.8321', '0.8294', '0.8393', '0.8404', '0.8491', '0.8529', '0.8554', '0.8666', '0.8639', '0.8739', '0.8760', '0.8821', '0.2067', '0.2930', '0.3376', '0.3671', '0.3829', '0.3971', '0.4057', '0.4144', '0.4226', '0.4367', '0.4436', '0.4511', '0.4526', '0.4719', '0.4707', '0.4790', '0.4844', '0.4934', '0.4964', '0.5034', '0.5146', '0.5163', '0.5234', '0.5289', '0.5353', '0.5421', '0.5490', '0.5587', '0.5616', '0.5749', '0.5700', '0.5817', '0.5859', '0.5977', '0.6011', '0.6063', '0.6107', '0.6180', '0.6224', '0.6320', '0.6389', '0.6443', '0.6434', '0.6489', '0.6674', '0.6624', '0.6661', '0.6746', '0.6834', '0.6840', '0.6921', '0.6894', '0.7073', '0.7086', '0.7171', '0.7179', '0.7243', '0.7357', '0.7320', '0.7436', '0.2090', '0.2967', '0.2947', '0.3001', '0.3103', '0.3243', '0.3374', '0.3454', '0.3526', '0.3644', '0.3689', '0.3727', '0.3811', '0.3846', '0.3850', '0.3913', '0.3931', '0.3999', '0.4129', '0.4120', '0.4124', '0.4173', '0.4217', '0.4300', '0.4246', '0.4330', '0.4374', '0.4386', '0.4401', '0.4490', '0.4469', '0.4511', '0.4587', '0.4630', '0.4659', '0.4621', '0.4711', '0.4754', '0.4790', '0.4766', '0.4786', '0.4810', '0.4861', '0.4950', '0.4879', '0.4960', '0.5004', '0.5057', '0.5080', '0.5054', '0.5096', '0.5164', '0.5176', '0.5200', '0.5203', '0.5251', '0.5306', '0.5290', '0.5381', '0.5356', '0.2113', '0.2456', '0.1851', '0.1963', '0.2037', '0.2164', '0.2313', '0.2323', '0.2390', '0.2464', '0.2513', '0.2554', '0.2557', '0.2639', '0.2679', '0.2730', '0.2761', '0.2780', '0.2787', '0.2850', '0.2877', '0.2811', '0.2856', '0.2894', '0.2971', '0.3020', '0.2937', '0.3023', '0.3126', '0.3146', '0.3133', '0.3111', '0.3240', '0.3237', '0.3261', '0.3259', '0.3223', '0.3331', '0.3306', '0.3337', '0.3369', '0.3340', '0.3410', '0.3340', '0.3451', '0.3437', '0.3481', '0.3473', '0.3484', '0.3523', '0.3511', '0.3546', '0.3591', '0.3610', '0.3523', '0.3543', '0.3633', '0.3599', '0.3657', '0.3683', '0.2181', '0.2420', '0.1180', '0.1303', '0.1421', '0.1443', '0.1500', '0.1524', '0.1634', '0.1551', '0.1650', '0.1651', '0.1643', '0.1699', '0.1647', '0.1653', '0.1690', '0.1641', '0.1709', '0.1773', '0.1724', '0.1793', '0.1756', '0.1829', '0.1713', '0.1771', '0.1729', '0.1811', '0.1764', '0.1836', '0.1754', '0.1840', '0.1790', '0.1850', '0.1886', '0.1837', '0.1874', '0.1834', '0.1836', '0.1853', '0.1910', '0.1823', '0.1894', '0.1869', '0.1824', '0.1846', '0.1871', '0.1950', '0.1910', '0.1900', '0.1837', '0.1881', '0.1963', '0.1937', '0.1946', '0.1920', '0.1973', '0.1964', '0.2013', '0.1971']\n",
      "[]\n",
      "['', '', '', '', '']\n",
      "['', '', '', '', '']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "val_acc_re = re.compile(\"(?:val_acc:)+ (\\d\\.+\\d+)\")\n",
    "train_acc_re = re.compile('(?: acc:)+ (\\d\\.+\\d+)')\n",
    "lambda_re = re.compile('(?:the reg is at \\=  )+(\\d+e-\\d+)+')\n",
    "sm_weight = re.compile('(?:the smallest weight is \\= )+(.*)+ ')\n",
    "bg_weight = re.compile('(?:the biggest weight is \\= )+(.*)+ ')\n",
    "mainstream_order = re.compile('(?:\\[\\(\\')+(.*)+\\)\\, ')\n",
    "\n",
    "val_mgroup = val_acc_re.findall(in1)\n",
    "train_mgroup = train_acc_re.findall(in1)\n",
    "lamb_mgroup = lambda_re.findall(in1)\n",
    "sm_mgroup = sm_weight.findall(in1)\n",
    "bg_mgroup = bg_weight.findall(in1)\n",
    "mo_mgroup = mainstream_order.findall(in1)\n",
    "\n",
    "print(val_mgroup)\n",
    "print(train_mgroup)\n",
    "print(lamb_mgroup)\n",
    "print(sm_mgroup)\n",
    "print(bg_mgroup)\n",
    "print(mo_mgroup)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
